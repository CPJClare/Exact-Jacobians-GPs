{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 4__Hessian__VIPER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rCIMJJrJ9Co"
      },
      "source": [
        "Pandemic Lockdown Modelling:  Bayesian optimization using VIPER\r\n",
        "\r\n",
        "GP EI: Newton-CG (exact GP EI Hessian) vs. L-BFGS-B (without Hessian)\r\n",
        "\r\n",
        "https://github.com/purushottamkar/esop\r\n",
        "\r\n",
        "https://arxiv.org/abs/2005.11257\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUs0l8uQL534",
        "outputId": "7efc194f-45a9-496c-93d5-c53a5162e898"
      },
      "source": [
        "!pip install pyGPGO"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyGPGO in /usr/local/lib/python3.7/dist-packages (0.4.0.dev1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (0.22.2.post1)\n",
            "Requirement already satisfied: pyMC3 in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.4.1)\n",
            "Requirement already satisfied: theano in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.5)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.5.1)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.1.5)\n",
            "Requirement already satisfied: h5py>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (2.10.0)\n",
            "Requirement already satisfied: tqdm>=4.8.4 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.41.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from theano->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->pyMC3->pyGPGO) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->pyMC3->pyGPGO) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3-VEXg5Jy_1"
      },
      "source": [
        "## Import modules\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import scipy\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pickle\r\n",
        "import random\r\n",
        "import warnings\r\n",
        "import time\r\n",
        "\r\n",
        "from pyGPGO.logger import EventLogger\r\n",
        "from pyGPGO.GPGO import GPGO\r\n",
        "from pyGPGO.surrogates.GaussianProcess import GaussianProcess\r\n",
        "from pyGPGO.acquisition import Acquisition\r\n",
        "from pyGPGO.covfunc import squaredExponential, matern52\r\n",
        "\r\n",
        "from collections import OrderedDict\r\n",
        "from joblib import Parallel, delayed\r\n",
        "from numpy.linalg import slogdet, inv, cholesky, solve\r\n",
        "from scipy.optimize import minimize\r\n",
        "from scipy.spatial.distance import cdist\r\n",
        "from scipy.stats import norm, binned_statistic as binStat\r\n",
        "from matplotlib.pyplot import rc\r\n",
        "rc('text', usetex=False)\r\n",
        "\r\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\r\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\r\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFYrttVTMVVE"
      },
      "source": [
        "### https://github.com/purushottamkar/esop/utils.py\r\n",
        "\r\n",
        "### https://arxiv.org/abs/2005.11257\r\n",
        "\r\n",
        "### VIPER Model\r\n",
        "\r\n",
        "# Convenient named constants for indices for various parameters pertaining to an individual in the VIPER model\r\n",
        "IDX_SUS = 0 # Susceptibility\r\n",
        "IDX_VLD = 1 # Viral load\r\n",
        "IDX_RLD = 2 # Recovery load\r\n",
        "IDX_RST = 3 # Resistance (never changed - intrinsic to the individual)\r\n",
        "IDX_X = 4   # X coordinate (only changed if the individual is travelling)\r\n",
        "IDX_Y = 5   # Y coordinate (only changed if the individual is travelling)\r\n",
        "IDX_STA = 6 # State\r\n",
        "IDX_QRN = 7 # Is this individual quarantined or not\r\n",
        "IDX_DPR = 8 # Disease progression rate\r\n",
        "IDX_TI = 9  # Timestamp of infection (only changed at time of infection)\r\n",
        "IDX_TQ = 10 # Timestamp of quarantine\r\n",
        "IDX_TR = 11 # Timestamp of recovery/expiry (only changed at time of recovery/expiry)\r\n",
        "\r\n",
        "nParams = 12\r\n",
        "\r\n",
        "sqrt2 = np.sqrt(2)\r\n",
        "\r\n",
        "# Convenient named constants for various states of an individual\r\n",
        "# Being quarantined is not a medical state and so it is tracked\r\n",
        "# separately (see IDX_QRN above) -- this allows VIPER to quarantine\r\n",
        "ST_S = 0\t# Susceptible\r\n",
        "ST_E = 1\t# Exposed\r\n",
        "ST_I = 2\t# Infectious\r\n",
        "ST_R = 3\t# Recovered\r\n",
        "ST_X = 4\t# Expired\r\n",
        "\r\n",
        "nStates = 5\r\n",
        "\r\n",
        "# Convenient named constants useful for reporting stats\r\n",
        "SIDX_S = 0\t# Number of susceptible but non-recovered individuals\r\n",
        "SIDX_E = 1\t# Number of exposed individuals\r\n",
        "SIDX_I = 2\t# Number of infectious individuals\r\n",
        "SIDX_Q = 3\t# Number of quarantined individuals\r\n",
        "SIDX_R = 4\t# Number of recovered individuals\r\n",
        "SIDX_X = 5\t# Number of expired individuals\r\n",
        "SIDX_V = 6\t# Average virulence of the viral strains in E and I populations\r\n",
        "SIDX_EI = 7\t# Number of infected individuals\r\n",
        "SIDX_D = 8\t# Number of individuals infected each day\r\n",
        "\r\n",
        "nStats = 9\r\n",
        "\r\n",
        "# This class provides an encapsulation for the VIPER model as well as methods\r\n",
        "# to perform epidemiological simulations under lock-down, quarantining etc\r\n",
        "class Population:\r\n",
        "\t# The base constructor -- almost never used directly\r\n",
        "\tdef __init__( self, N, BIR, BCR, INC, BVL, VMR, QTH, BQP, XTH, BXP, BTR, BTD, BDPR, alphaInit, popIdx, ind, SUS, RST, X, Y ):\r\n",
        "\t\tself.N = N\r\n",
        "\t\tself.BIR = BIR\r\n",
        "\t\tself.BCR = BCR\r\n",
        "\t\tself.INC = INC\r\n",
        "\t\tself.BVL = BVL\r\n",
        "\t\tself.VMR = VMR\r\n",
        "\t\tself.QTH = QTH\r\n",
        "\t\tself.BQP = BQP\r\n",
        "\t\tself.XTH = XTH\r\n",
        "\t\tself.BXP = BXP\r\n",
        "\t\tself.BTR = BTR\r\n",
        "\t\tself.BTD = BTD\r\n",
        "\t\tself.BDPR = BDPR\r\n",
        "\t\tself.alphaInit = alphaInit\r\n",
        "\t\t\r\n",
        "\t\tself.popIdx = popIdx\r\n",
        "\t\tself.ind = ind\r\n",
        "\t\tself.SUS = SUS\r\n",
        "\t\tself.RST = RST\r\n",
        "\t\tself.X = X\r\n",
        "\t\tself.Y = Y\r\n",
        "\t\r\n",
        "\t# Constructor that initializes using scalar values alone\r\n",
        "\t# This provides a generic population with location, SUS, RST values\r\n",
        "\t# set uniformly randomly. To use India-specific initialization, use\r\n",
        "\t# the patch provided by the class Demographics (see below and setup.py)\r\n",
        "\t\r\n",
        "\t# N: the size of the population before the pandemic began\r\n",
        "\t# BIR: the (base) probability that a contact event will lead to a successful infection\r\n",
        "\t# BCR: the (base) contact radius\r\n",
        "\t# INC: the incubation period for the virus\r\n",
        "\t# BVL: the base viral load presented in individuals at the end of the exposed period\r\n",
        "\t# VMR: the rate at which the DPR mutates upon contact\r\n",
        "\t# QTH: the viral load over which an individual's chances of getting quarantined increase linearly\r\n",
        "\t# BQP: the (base) quarantining probability for a person with viral load at the QTH threshold\r\n",
        "\t# XTH: the viral load over which an individual's chances of getting expired increase linearly\r\n",
        "\t# BXP: the (base) expiry probability for a person with viral load at the XTH threshold\r\n",
        "\t# BTR: the (base) fraction of population that travels at any time instant\r\n",
        "\t# BTD: the (base) distance to which people travel\r\n",
        "\t# BDPR: the (base) disease progression rate for the initial strain of the virus\r\n",
        "\t# alphaInit: the initial fraction of population that is infected with the virus\r\n",
        "\t@classmethod\r\n",
        "\tdef valInit( cls, N, BIR = 0.5, BCR = 0.25, INC = 3, BVL = 0.05, VMR = 0.0, QTH = 0.3, BQP = 0.0, XTH = 0.7, BXP = 0.0, BTR = 0.01, BTD = 1.0, BDPR = 0.1, alphaInit = 0.01 ):\r\n",
        "\t\t# Give the individuals unique identifiers\r\n",
        "\t\tpopIdx = np.arange(N)\r\n",
        "\t\t\r\n",
        "\t\t# Initialize the individuals\r\n",
        "\t\tind = np.zeros( (N, nParams) )\r\n",
        "\r\n",
        "\t\t# Initially no one is infected or quarantined\r\n",
        "\t\tind[ :, IDX_VLD ] = 0\r\n",
        "\t\tind[ :, IDX_RLD ] = 0\r\n",
        "\t\tind[ :, IDX_STA ] = ST_S\r\n",
        "\t\tind[ :, IDX_DPR ] = 0\r\n",
        "\t\tind[ :, IDX_QRN ] = 0\r\n",
        "\t\t\r\n",
        "\t\t# People have susceptibilities uniformly in a range\r\n",
        "\t\t# The patch offered by the Demographics class allows this to be changed\r\n",
        "\t\tSUS = np.random.uniform( 0.01, 0.99, (N,) )\r\n",
        "\t\tind[ :, IDX_SUS ] = SUS\r\n",
        "\t\t\r\n",
        "\t\t# People have resistances uniformly in a range\r\n",
        "\t\t# The patch offered by the Demographics class allows this to be changed\r\n",
        "\t\tRST = 0.1 * np.random.uniform( 0.01, 0.99, (N,) )\r\n",
        "\t\tind[ :, IDX_RST ] = RST\r\n",
        "\r\n",
        "\t\t# Set their locations uniformly at random within the [0,1] x [0,1] square\r\n",
        "\t\t# The patch offered by the Demographics class allows this to be changed\r\n",
        "\t\tX = np.random.uniform( 0, 1, (N,) )\r\n",
        "\t\tind[ :, IDX_X ] = X\r\n",
        "\t\tY = np.random.uniform( 0, 1, (N,) )\r\n",
        "\t\tind[ :, IDX_Y ] = Y\r\n",
        "\t\t\r\n",
        "\t\t# Set the timers to invalid values since nothing has happened yet\r\n",
        "\t\tind[ :, IDX_TI ] = 0\r\n",
        "\t\tind[ :, IDX_TQ ] = 0\r\n",
        "\t\tind[ :, IDX_TR ] = 0\r\n",
        "\t\t\r\n",
        "\t\treturn cls( N, BIR, BCR, INC, BVL, VMR, QTH, BQP, XTH, BXP, BTR, BTD, BDPR, alphaInit, popIdx, ind, SUS, RST, X, Y )\r\n",
        "\t\r\n",
        "\t# Constructor that initializes using data loaded from file\r\n",
        "\t@classmethod\r\n",
        "\tdef fileInit( cls, filename ):\r\n",
        "\t\t# Get data from the file\r\n",
        "\t\twith open( filename, 'rb' ) as file:\r\n",
        "\t\t\tdata = pickle.load( file )\r\n",
        "\t\t\r\n",
        "\t\t# Create an object out of this data and return it\r\n",
        "\t\treturn cls( *data )\r\n",
        "\t\t\r\n",
        "\t# Save a copy of this object to a file\r\n",
        "\tdef dump( self, filename ):\r\n",
        "\t\tdata = ( self.N, self.BIR, self.BCR, self.INC, self.BVL, self.VMR, self.QTH, self.BQP, self.XTH, self.BXP, self.BTR, self.BTD, self.BDPR, self.alphaInit, self.popIdx, self.ind, self.SUS, self.RST, self.X, self.Y )\r\n",
        "\t\twith open( filename, 'wb' ) as file:\r\n",
        "\t\t\tpickle.dump( data, file )\r\n",
        "\t\t\t\r\n",
        "\t# Turn the clock back to before the pandemic started\r\n",
        "\tdef reset( self ):\r\n",
        "\t\t# Reinitialize the individuals\r\n",
        "\t\tself.ind.fill(0)\r\n",
        "\t\t\r\n",
        "\t\t# Reset their susceptibilities to their original values (they do change for recovered and expired individuals)\r\n",
        "\t\tself.ind[ :, IDX_SUS ] = self.SUS\r\n",
        "\t\t\t\t\t\t\t \r\n",
        "\t\t# Initially no one is infected or quarantined\r\n",
        "\t\tself.ind[ :, IDX_VLD ] = 0\r\n",
        "\t\tself.ind[ :, IDX_RLD ] = 0\r\n",
        "\t\tself.ind[ :, IDX_STA ] = ST_S\r\n",
        "\t\tself.ind[ :, IDX_DPR ] = 0\r\n",
        "\t\tself.ind[ :, IDX_QRN ] = 0\r\n",
        "\t\t\t\t\t\t\t \r\n",
        "\t\t# Reset their resistances to their original value (although they should not have changed)\r\n",
        "\t\tself.ind[ :, IDX_RST ] = self.RST\r\n",
        "\t\t\t\t  \r\n",
        "\t\t# Reset their locations\r\n",
        "\t\tself.ind[ :, IDX_X ] = self.X\r\n",
        "\t\tself.ind[ :, IDX_Y ] = self.Y\r\n",
        "\t\t\t\t  \r\n",
        "\t\t# Reset the timers to a happier time before the pandemic began\r\n",
        "\t\tself.ind[ :, IDX_TI ] = 0\r\n",
        "\t\tself.ind[ :, IDX_TQ ] = 0\r\n",
        "\t\tself.ind[ :, IDX_TR ] = 0\r\n",
        "\t\t\r\n",
        "\t# T: the number of time steps for which to run the simulation\r\n",
        "\t# LKP: the lock-down policy\r\n",
        "\tdef simulate( self, T, LKP, minimal = False, checkSanity = False ):\r\n",
        "\t\tnumInfInit = int( self.alphaInit * self.N )\r\n",
        "\t\t\r\n",
        "\t\t# Randomly select the unfortunate souls who are going to get infected initially\r\n",
        "\t\tidxInit = np.random.permutation( self.N )[ : numInfInit ]\r\n",
        "\t\t\r\n",
        "\t\t# Infect them!\r\n",
        "\t\tself.ind[ idxInit, IDX_STA ] = ST_E\t\t\t# These individuals are incubating right now\r\n",
        "\t\tself.ind[ idxInit, IDX_DPR ] = self.BDPR\t# The virus has not mutated yet\r\n",
        "\t\tself.ind[ idxInit, IDX_TI ] = 1\t\t\t\t# They got infected at t = 1\r\n",
        "\t\t\r\n",
        "\t\t# Store the intial stats\r\n",
        "\t\tstats = np.zeros( (nStats, T+1) )\r\n",
        "\t\tstats[ :, 0 ] = np.array( [ self.N - numInfInit, numInfInit, 0, 0, 0, 0, self.BDPR, numInfInit, numInfInit ] )\r\n",
        "\t\t\r\n",
        "\t\tfor t in range(T):\r\n",
        "\t\t\tif checkSanity:\r\n",
        "\t\t\t\tself.doSanityChecks()\r\n",
        "\t\t\t# Track the progress of disease in infected + exposed individuals\r\n",
        "\t\t\tself.letDiseaseProgress( t+2 )\r\n",
        "\t\t\t# As much as permitted by the lock-down level at this time instant, allow individuals to travel\r\n",
        "\t\t\tself.letIndividualsTravel( LKP[t] )\r\n",
        "\t\t\t# Allow interactions and fresh infections and get a daily count\r\n",
        "\t\t\tdaily = self.letIndividualsInfect( LKP[t], t+2 )\r\n",
        "\t\t\t# As dictated by the quarantine policy, catch and quarantine individuals\r\n",
        "\t\t\tself.applyQuarantinePolicy( t+2 )\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Compute essential statistics\r\n",
        "\t\t\tidxEorI = (self.ind[ :, IDX_STA ].astype( int ) == ST_E) | (self.ind[ :, IDX_STA ].astype( int ) == ST_I)\r\n",
        "\t\t\tstats[ SIDX_EI, t+1 ] = np.count_nonzero( idxEorI )\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Compute optional statistics\r\n",
        "\t\t\tif not minimal:\r\n",
        "\t\t\t\tstats[ SIDX_S, t+1 ] = np.count_nonzero( self.ind[ :, IDX_STA ].astype( int ) == ST_S )\r\n",
        "\t\t\t\tstats[ SIDX_E, t+1 ] = np.count_nonzero( self.ind[ :, IDX_STA ].astype( int ) == ST_E )\r\n",
        "\t\t\t\tstats[ SIDX_I, t+1 ] = np.count_nonzero( self.ind[ :, IDX_STA ].astype( int ) == ST_I )\r\n",
        "\t\t\t\tstats[ SIDX_Q, t+1 ] = np.count_nonzero( self.ind[ :, IDX_QRN ].astype( int ) == 1 )\r\n",
        "\t\t\t\tstats[ SIDX_R, t+1 ] = np.count_nonzero( self.ind[ :, IDX_STA ].astype( int ) == ST_R )\r\n",
        "\t\t\t\tstats[ SIDX_X, t+1 ] = np.count_nonzero( self.ind[ :, IDX_STA ].astype( int ) == ST_X )\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\tstats[ SIDX_D, t+1 ] = daily\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\tif len(idxEorI) == 0:\r\n",
        "\t\t\t\t\tstats[ SIDX_V, t+1 ] = 0\r\n",
        "\t\t\t\telse:\r\n",
        "\t\t\t\t\tstats[ SIDX_V, t+1 ] = np.mean( self.ind[ idxEorI, IDX_DPR ] )\r\n",
        "\t\t\r\n",
        "\t\t# Simulation over!!\r\n",
        "\t\t\r\n",
        "\t\t# Compute disease progression statistics and return final results of the simulation\r\n",
        "\t\tif minimal:\r\n",
        "\t\t\treturn stats\r\n",
        "\t\telse:\r\n",
        "\t\t\tidxEverInfected = self.ind[ :, IDX_TI ].astype( int ) > 0\r\n",
        "\t\t\ttInfect = self.ind[ idxEverInfected, IDX_TI ]\r\n",
        "\t\t\t\r\n",
        "\t\t\tidxQuarantined = self.ind[ :, IDX_TQ ].astype( int ) > 0\r\n",
        "\t\t\ttQuarantine = self.ind[ idxQuarantined, IDX_TQ ] - self.ind[ idxQuarantined, IDX_TI ]\r\n",
        "\t\t\t\r\n",
        "\t\t\tidxRecovered = self.ind[ :, IDX_STA ].astype( int ) == ST_R\r\n",
        "\t\t\ttRecovery = self.ind[ idxRecovered, IDX_TR ] - self.ind[ idxRecovered, IDX_TI ]\r\n",
        "\t\t\t\r\n",
        "\t\t\tidxExpired = self.ind[ :, IDX_STA ].astype( int ) == ST_X\r\n",
        "\t\t\ttExpiry = self.ind[ idxExpired, IDX_TR ] - self.ind[ idxExpired, IDX_TI ]\r\n",
        "\t\t\t\r\n",
        "\t\t\treturn ( stats, tInfect, tQuarantine, tRecovery, tExpiry )\r\n",
        "\t\t\t\r\n",
        "\t\r\n",
        "\t# Simulate incubation period, update viral and recovery loads, and process expiries and recoveries\r\n",
        "\tdef letDiseaseProgress( self, t ):\r\n",
        "\t\t# Process recoveries of infectious individuals\r\n",
        "\t\t# TODO: recovery does not necessarily grant immunity: high levels of immunity may\r\n",
        "\t\t# only be available to those in whom the disease did progress sufficiently\r\n",
        "\t\tidxRecovered = ((self.ind[ :, IDX_STA ].astype( int ) == ST_I) & (self.ind[ :, IDX_VLD ] < self.BVL))\r\n",
        "\t\tif len(idxRecovered) > 0:\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_TR ] = t\t\t# These people recovered at time t\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_SUS ] = 0\t\t# They are now immune from the disease\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_VLD ] = 0\t\t# Their remaining viral load vanishes in an instant\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_RLD ] = 0\t\t# Their recovery load is made good instantly\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_STA ] = ST_R\t# They are now recovered\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_DPR ] = 0\t\t# They are free of the virus\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_QRN ] = 0\t\t# They are released from any quarantine in which they may have been\r\n",
        "\t\t\r\n",
        "\t\t# Process expiries of infectious individuals\r\n",
        "\t\t# If expiry threshold is too high, assume no one is going to get expired!\r\n",
        "\t\tif self.XTH < 1 - 1e-6:\r\n",
        "\t\t\tidxExpiryRisk = self.popIdx[ (self.ind[ :, IDX_STA ].astype( int ) == ST_I) & (self.ind[ :, IDX_VLD ] > self.XTH) ]\r\n",
        "\t\t\tif len(idxExpiryRisk) > 0:\r\n",
        "\t\t\t\texpiryProb = self.BXP + ( 1 - self.BXP ) * (self.ind[ idxExpiryRisk, IDX_VLD ] - self.XTH)/(1 - self.XTH)\r\n",
        "\t\t\t\ttosses = np.random.uniform( 0, 1, ( len(expiryProb), ) )\r\n",
        "\t\t\t\tidxExpired = idxExpiryRisk[ tosses < expiryProb ]\r\n",
        "\t\t\t\tif len(idxExpired) > 0:\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_TR ] = t\t\t# These people expired at time t\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_SUS ] = 0\t\t# Either way, they are now immune from the disease\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_VLD ] = 0\t\t# Their remaining viral load vanishes in an instant\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_RLD ] = 0\t\t# Their recovery load does not matter any more\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_STA ] = ST_X\t# They are removed from the population\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_DPR ] = 0\t\t# Either way, they are now free of the virus\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_QRN ] = 0\t\t# They are released from any quarantine in which they may have been\r\n",
        "\t\t\r\n",
        "\t\t# Update viral and recovery loads\r\n",
        "\t\tidxInfected = self.popIdx[ self.ind[ :, IDX_STA ].astype( int ) == ST_I ]\r\n",
        "\t\tif len(idxInfected) > 0:\r\n",
        "\t\t\t# Some of the viral load is shed into recovery load, depending on the resistance of the person\r\n",
        "\t\t\tVLD_DeltaNeg = self.ind[ idxInfected, IDX_RST ] * self.ind[ idxInfected, IDX_VLD ]\r\n",
        "\t\t\t# The viral load also goes up, depending on the disease progression rate\r\n",
        "\t\t\tNormalLoad = 1 - self.ind[ idxInfected, IDX_VLD ] - self.ind[ idxInfected, IDX_RLD ]\r\n",
        "\t\t\tVLD_DeltaPos = NormalLoad * self.ind[ idxInfected, IDX_DPR ]\r\n",
        "\t\t\t\r\n",
        "\t\t\tself.ind[ idxInfected, IDX_RLD ] += VLD_DeltaNeg\r\n",
        "\t\t\tself.ind[ idxInfected, IDX_VLD ] += (VLD_DeltaPos - VLD_DeltaNeg)\r\n",
        "\t\t\r\n",
        "\t\t# Process incubation maturity cases\r\n",
        "\t\tidxExposed = self.popIdx[ self.ind[ :, IDX_STA ].astype( int ) == ST_E ]\r\n",
        "\t\tif len(idxExposed) > 0:\r\n",
        "\t\t\ttExposed = self.ind[ idxExposed, IDX_TI ].astype( int )\r\n",
        "\t\t\tidxMatured = idxExposed[ tExposed == t - self.INC ]\r\n",
        "\t\t\tif len(idxMatured) > 0:\r\n",
        "\t\t\t\tself.ind[ idxMatured, IDX_VLD ] = self.BVL\t# These people now have a base viral load\r\n",
        "\t\t\t\tself.ind[ idxMatured, IDX_STA ] = ST_I\t# They are now infectious\r\n",
        "\t\t\t\t\r\n",
        "\t# Let individuals travel according to the current lock-down level\r\n",
        "\tdef letIndividualsTravel( self, level ):\r\n",
        "\t\t# Only non-quarantined and non-expired individuals can travel\r\n",
        "\t\tidxTravelAllowed = self.popIdx[ (self.ind[ :, IDX_QRN ].astype( int ) == 0) & (self.ind[ :, IDX_STA ].astype( int ) != ST_X) ]\r\n",
        "\t\tif len(idxTravelAllowed) > 0:\r\n",
        "\t\t\tnTravelAllowed = len(idxTravelAllowed)\r\n",
        "\t\t\tnTravellers = int( nTravelAllowed * self.BTR )\r\n",
        "\t\t\tif nTravellers > 0:\r\n",
        "\t\t\t\t# Allow a random set of people who are allowed to travel, to do so\r\n",
        "\t\t\t\tidxTravellers = idxTravelAllowed[ np.random.permutation( nTravelAllowed )[ :nTravellers ] ]\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\t# The travel distance is limited by the lock-down level\r\n",
        "\t\t\t\ttDist = self.BTD * np.exp( -level )\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\t# Dividing by sqrt2 since perturbations are made to two dimensions\r\n",
        "\t\t\t\ttravelX = tDist / sqrt2 * np.random.uniform( -1, 1, (nTravellers,) )\r\n",
        "\t\t\t\ttravelY = tDist / sqrt2 * np.random.uniform( -1, 1, (nTravellers,) )\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\t# Make sure individuals do not travel to another planet or something\r\n",
        "\t\t\t\tself.ind[ idxTravellers, IDX_X ] = ( self.ind[ idxTravellers, IDX_X ] + travelX ) % 1\r\n",
        "\t\t\t\tself.ind[ idxTravellers, IDX_Y ] = ( self.ind[ idxTravellers, IDX_Y ] + travelY ) % 1\r\n",
        "\t\t\r\n",
        "\t# Let individuals infect each other based on the current lock-down level\r\n",
        "\tdef letIndividualsInfect( self, level, t ):\r\n",
        "\t\t# All non-quarantined non-expired individuals can participate in interactions\r\n",
        "\t\t# Individuals going through the incubation period do participate but neither infect nor can be infected\r\n",
        "\t\tidxParticipants = self.popIdx[ (self.ind[ :, IDX_QRN ].astype( int ) == 0) & (self.ind[ :, IDX_STA ].astype( int ) != ST_X) ]\r\n",
        "\t\t# Find a mask for the (non-quarantined) infectious participants\r\n",
        "\t\tmaskInfectious = self.ind[ idxParticipants, IDX_STA ].astype( int ) == ST_I\r\n",
        "\t\t# Find a mask for non-immune susceptible/recovered individuals\r\n",
        "\t\tmaskSusceptible = (self.ind[ idxParticipants, IDX_SUS ] > 0) & ( (self.ind[ idxParticipants, IDX_STA ].astype( int ) == ST_S) | (self.ind[ idxParticipants, IDX_STA ].astype( int ) == ST_R) )\r\n",
        "\t\t\r\n",
        "\t\t# If there is either no one infecting or else no one to infect, nothing left to do\r\n",
        "\t\tif ( np.count_nonzero( maskInfectious ) == 0 ) | ( np.count_nonzero( maskSusceptible ) == 0 ):\r\n",
        "\t\t\treturn 0\r\n",
        "\t\t\r\n",
        "\t\t# Jiggle the coordinates pf the participants a bit to simulate random interactions\r\n",
        "\t\t# The jiggle dies down with lock-down level\r\n",
        "\t\tXParticipants = self.ind[ idxParticipants, IDX_X:IDX_Y + 1 ]\r\n",
        "\t\tjitter = self.BCR * np.exp( -level ) / sqrt2 * np.random.uniform( 0, 1, (2,) )\r\n",
        "\t\tXParticipants += jitter\r\n",
        "\t\t\r\n",
        "\t\t# Create interaction bins out of these jittered coordinates\r\n",
        "\t\t# The jitter added earlier allows individuals to fall into potentially different bins each time\r\n",
        "\t\t# TODO: this is slow at the moment, especially at high lock-down levels when number of bins\r\n",
        "\t\t# skyrockets since everyone is trapped inside their virtual houses. Speed this up by using a\r\n",
        "\t\t# reverse hash to iterate only over non-empty bins (there can be at most N such bins)\r\n",
        "\t\trContact = self.BCR * np.exp( -level ) / sqrt2\r\n",
        "\t\tXParticipants = np.floor( XParticipants / rContact )\r\n",
        "\t\tnBinsPerCoord = np.max( XParticipants ) + 1\r\n",
        "\t\tBParticipants = ( XParticipants[:, 0] * nBinsPerCoord + XParticipants[:, 1] ).astype( int )\r\n",
        "\t\t\r\n",
        "\t\t# Find the bins for infectious and susceptible individuals\r\n",
        "\t\tBInfectious = BParticipants[ maskInfectious ]\r\n",
        "\t\tBSusceptible = BParticipants[ maskSusceptible ]\r\n",
        "\t\t\r\n",
        "\t\t# Find the infection probabilities in each bin\r\n",
        "\t\tbins = np.arange( np.max(BParticipants) + 2 )\r\n",
        "\t\t# print( \"At time %d, we have jitter (%f, %f) and %d bins\" % ( t, jitter[0], jitter[1], len(bins) ) )\r\n",
        "\t\tbinParticipantCount = np.histogram( BParticipants, bins )[0]\r\n",
        "\t\tbinParticipantCount[ binParticipantCount < 1 ] = 1 # Avoid a divide-by-zero error\r\n",
        "\t\tbinInfectiousCount = np.histogram( BInfectious, bins )[0]\r\n",
        "\t\tbinInfectionProb = binInfectiousCount / binParticipantCount * self.BIR\r\n",
        "\t\t\r\n",
        "\t\t# Find the mean DPR within each bin -- this will be used to decide the DPR for newly infected people\r\n",
        "\t\tidxInfectious = idxParticipants[maskInfectious]\r\n",
        "\t\tbinDPR = binStat( BInfectious, self.ind[ idxInfectious, IDX_DPR ], statistic = \"mean\", bins = bins )[0]\r\n",
        "\t\tbinDPR[ np.isnan( binDPR ) ] = 0 # Fix values for bins where there were no infectious people\r\n",
        "\t\t\r\n",
        "\t\t# Find the infection probabilities for each susceptible individual\r\n",
        "\t\tidxSusceptible = idxParticipants[maskSusceptible]\r\n",
        "\t\tinfectionProb = binInfectionProb[BSusceptible] * self.ind[ idxSusceptible, IDX_SUS ]\r\n",
        "\t\t\r\n",
        "\t\t# Find new DPRs for the mutated viruses for the susceptible individuals\r\n",
        "\t\t# Currently this bit of code has been inactivated since we have set VMR = 0.0\r\n",
        "\t\tnewDPR = binDPR[BSusceptible] * ( 1 + self.VMR * ( 2 * np.random.randint( 0, 2, ( len(BSusceptible), ) ) - 1 ) )\r\n",
        "\t\tnewDPR[ newDPR < 0.001 ] = 0.001 # Make sure DPR never dips too low\r\n",
        "\t\tnewDPR[ newDPR > 0.999 ] = 0.999 # Make sure DPR never goes too high\r\n",
        "\t\t\r\n",
        "\t\t# Get some random bits to decide who gets infected among the susceptible\r\n",
        "\t\ttosses = np.random.uniform( 0, 1, ( len(infectionProb), ) )\r\n",
        "\t\tmaskInfected = tosses < infectionProb\r\n",
        "\t\tidxInfected = idxSusceptible[maskInfected]\r\n",
        "\t\tif len(idxInfected) > 0:\r\n",
        "\t\t\tself.ind[ idxInfected, IDX_STA ] = ST_E\t\t\t\t\t\t# These individuals are incubating right now\r\n",
        "\t\t\tself.ind[ idxInfected, IDX_DPR ] = newDPR[maskInfected]\t\t# These individuals get the mutated version\r\n",
        "\t\t\tself.ind[ idxInfected, IDX_TI ] = t\t\t\t\t\t\t\t# They got infected at t = t\r\n",
        "\t\t\t\r\n",
        "\t\treturn len(idxInfected)\r\n",
        "\t\t\r\n",
        "\t# Quarantine individuals based on quarantine policy\r\n",
        "\tdef applyQuarantinePolicy( self, t ):\r\n",
        "\t\t# If quarantine threshold is too high, assume no one is going to get quarantined!\r\n",
        "\t\tif self.QTH > 1 - 1e-6:\r\n",
        "\t\t\treturn\r\n",
        "\t\t\t\r\n",
        "\t\t# Only non-quarantined and non-expired individuals with viral loads above the quarantine threshold can be quarantined\r\n",
        "\t\tidxPotential = self.popIdx[ ( self.ind[ :, IDX_QRN ].astype( int ) == 0 ) & ( self.ind[ :, IDX_STA ].astype( int ) != ST_X ) & ( self.ind[ :, IDX_VLD ] > self.QTH ) ]\r\n",
        "\t\tif len(idxPotential) > 0:\r\n",
        "\t\t\tquarantineProb = self.BQP + ( 1 - self.BQP ) * ( self.ind[ idxPotential, IDX_VLD ] - self.QTH ) / ( 1 - self.QTH )\r\n",
        "\t\t\ttosses = np.random.uniform( 0, 1, ( len(quarantineProb), ) )\r\n",
        "\t\t\tidxQuarantined = idxPotential[ tosses < quarantineProb ]\r\n",
        "\t\t\tif len(idxQuarantined) > 0:\r\n",
        "\t\t\t\tself.ind[ idxQuarantined, IDX_QRN ] = 1\t\t# Put them in quarantine\r\n",
        "\t\t\t\tself.ind[ idxQuarantined, IDX_TQ ] = t\t\t# Note down the time of quarantining\r\n",
        "\t\t\t\t\r\n",
        "\t# Do sanity checks to make sure there are no anomalies\r\n",
        "\tdef doSanityChecks( self ):\r\n",
        "\t\t# Make sure there are no negative values anywhere\r\n",
        "\t\tminVal = np.min( self.ind )\r\n",
        "\t\tassert minVal >= 0, \"Negative values detected in the parameter values: %f\" % minVal\r\n",
        "\t\r\n",
        "\t\t# Make sure everyone is in one of the five states S, E, I, R, X\r\n",
        "\t\tstates = set( np.unique( self.ind[ :, IDX_STA ] ).astype( int ) )\r\n",
        "\t\tgold = set( np.arange( nStates ) )\r\n",
        "\t\tassert len( states - gold ) == 0, \"Invalid states detected %\" % \"\".join([str(i)+\", \" for i in states])\r\n",
        "\t\t\r\n",
        "\t\t# Make sure no one except those in I state have a non-zero viral and recovery load\r\n",
        "\t\tidxNonInfected = (self.ind[ :, IDX_STA ].astype( int ) != ST_I)\r\n",
        "\t\tassert max( self.ind[ idxNonInfected, IDX_VLD ] ) < 1e-6, \"Non-infectious individuals with non-zero viral load detected\"\r\n",
        "\t\tassert max( self.ind[ idxNonInfected, IDX_RLD ] ) < 1e-6, \"Non-infectious individuals with non-zero recovery load detected\"\r\n",
        "\t\t\r\n",
        "\t\t# Make sure no one other than those in state I are in quarantine\r\n",
        "\t\t# This may have to be modified if VIPER is extended to enable false positives in quarantining\r\n",
        "\t\tidxInvalidQuarantine = self.popIdx[ (self.ind[ :, IDX_QRN ].astype( int ) == 1) & (self.ind[ :, IDX_STA ].astype( int ) != ST_I) ]\r\n",
        "\t\tassert len(idxInvalidQuarantine) == 0, \"Non-infectious individuals quarantined\"\r\n",
        "\t\t\r\n",
        "\t\t# Make sure all individual locations are within bounds\r\n",
        "\t\tminX = np.min( self.ind[ :, IDX_X ] )\r\n",
        "\t\tassert minX >= 0, \"Negative values detected in X coordinates %f\" % minX\r\n",
        "\t\tminY = np.min( self.ind[ :, IDX_Y ] )\r\n",
        "\t\tassert minY >= 0, \"Negative values detected in Y coordinates %f\" % minY\r\n",
        "\t\tmaxX = np.max( self.ind[ :, IDX_X ] )\r\n",
        "\t\tassert maxX <= 1, \"Large values detected in X coordinates %f\" % maxX\r\n",
        "\t\tmaxY = np.max( self.ind[ :, IDX_Y ] )\r\n",
        "\t\tassert maxY <= 1, \"Large values detected in Y coordinates %f\" % maxY\r\n",
        "\t\t\r\n",
        "# This class provides patches to the SUS, RST and location parameters for an object of the\r\n",
        "# Population class. RST and SUS values are fitted to Indian statistics and locations are\r\n",
        "# clustered into cities for a certain fraction of the population.\r\n",
        "class Demographics:\r\n",
        "\t# The base constructor -- almost never used directly\r\n",
        "\tdef __init__( self, N, urbanRatio, numCities, cityRadius, loc, isUrban, cityCenters, cityIdx, demoData ):\r\n",
        "\t\tself.N = N\r\n",
        "\t\tself.urbanRatio = urbanRatio\r\n",
        "\t\tself.numCities = numCities\r\n",
        "\t\tself.cityRadius = cityRadius\r\n",
        "\t\tself.loc = loc\r\n",
        "\t\tself.isUrban = isUrban\r\n",
        "\t\tself.cityCenters = cityCenters\r\n",
        "\t\tself.cityIdx = cityIdx\r\n",
        "\t\tself.demoData = demoData\r\n",
        "\t\r\n",
        "\t# Constructor that initializes using scalar values for various parameters\r\n",
        "\t# This provides a patch to the generic population generated using the class\r\n",
        "\t# Population (see above and setup.py) with a certain fraction living in cities\r\n",
        "\t# and RST and SUS values distributed to fit India statistics\r\n",
        "\t\r\n",
        "\t# N: the size of the population before the pandemic began\r\n",
        "\t# urbanRatio: what fraction of this population lives in cities?\r\n",
        "\t# numCities: how many cities do we have\r\n",
        "\t# cityRadius: the soft geographical extent of each city. ~99.7 of the population\r\n",
        "\t# of any city should live within 3 x cityRadius distance of the city center\r\n",
        "\t@classmethod\r\n",
        "\tdef valInit( cls, N, urbanRatio = 0.34, numCities = 4, cityRadius = 0.1 ):\r\n",
        "\t\t( loc, isUrban, cityCenters, cityIdx ) = cls.getInitLocations( N, urbanRatio, numCities, cityRadius )\r\n",
        "\t\tdemoData = cls.getDemographics(N)\r\n",
        "\t\treturn cls( N, urbanRatio, numCities, cityRadius, loc, isUrban, cityCenters, cityIdx, demoData )\r\n",
        "\t\t\r\n",
        "\t# Constructor that initializes using data loaded from file\r\n",
        "\t@classmethod\r\n",
        "\tdef fileInit( cls, filename ):\r\n",
        "\t\t# Get data from the file\r\n",
        "\t\twith open( filename, 'rb' ) as file:\r\n",
        "\t\t\tdata = pickle.load( file )\r\n",
        "\t\t\r\n",
        "\t\t# Create an object out of this data and return it\r\n",
        "\t\treturn cls( *data )\r\n",
        "\t\t\r\n",
        "\t# Save a copy of this object to a file\r\n",
        "\tdef dump( self, filename ):\r\n",
        "\t\tdata = ( self.N, self.urbanRatio, self.numCities, self.cityRadius, self.loc, self.isUrban, self.cityCenters, self.cityIdx, self.demoData )\r\n",
        "\t\twith open( filename, 'wb' ) as file:\r\n",
        "\t\t\tpickle.dump( data, file )\r\n",
        "\t\t\t\r\n",
        "\t# Distribute people into cities and non-urban areas randomly as requested\r\n",
        "\t@classmethod\r\n",
        "\tdef getInitLocations( cls, N, urbanRatio, numCities, cityRadius ):\r\n",
        "\t\tloc = np.zeros( (N, 2) )\r\n",
        "\t\tisUrban = np.zeros( (N,) )\r\n",
        "\t\t\r\n",
        "\t\t# Find out who all is living in the cities\r\n",
        "\t\tnumUrban = int( N * urbanRatio )\r\n",
        "\t\tpermLoc = np.random.permutation( N )\r\n",
        "\t\tisUrban[ permLoc[ : numUrban ] ] = 1\r\n",
        "\t\t\r\n",
        "\t\t# Non-urban populations are distributed uniformly randomly\r\n",
        "\t\tloc[ permLoc[ numUrban : ], : ] = np.random.uniform( 0, 1, ( N - numUrban, 2 ) )\r\n",
        "\t\t\r\n",
        "\t\t# Urban populations are distributed in clusters around city centers\r\n",
        "\t\t# First, let us find the city centers\r\n",
        "\t\tcityCenters = np.random.uniform( 0, 1, ( numCities, 2 ) )\r\n",
        "\t\t# Next, assign each city dweller, a city uniformly randomly\r\n",
        "\t\tcityIdx = np.random.randint( 0, numCities, (numUrban,) )\r\n",
        "\t\t# Finally, set the location of each city dweller as a jitter around their respective city centers\r\n",
        "\t\tloc[ permLoc[ : numUrban ], : ] = cityCenters[ cityIdx, : ]\r\n",
        "\t\tloc[ permLoc[ : numUrban ], : ] += np.random.normal( 0, cityRadius / sqrt2, ( numUrban, 2 ) )\r\n",
        "\t\t\r\n",
        "\t\t# Make sure no one leaves the planet!\r\n",
        "\t\tloc[ loc < 0 ] = 0\r\n",
        "\t\tloc[ loc > 1 ] = 1\r\n",
        "\t\t\r\n",
        "\t\treturn ( loc, isUrban, cityCenters, cityIdx )\r\n",
        "\t\r\n",
        "\t# Get RST and SUS values for the population that are derived from India statistics. For references\r\n",
        "\t# mentioned below e.g. (Ramakrishnan et al. 2019), please refer to the ESOP paper\r\n",
        "\t# https://arxiv.org/abs/2005.11257\r\n",
        "\t\r\n",
        "\t# Age groups are 0-20, 20-30, 30-40, 40-45, 45-50, 50-55, 55-60, 60-65, 65-70, 70-75, 75-80, 80+\r\n",
        "\t# There are 12 age groups that are indexed 0 through 11\r\n",
        "\t# This funny splitting of groups is due to the way in which various papers report their statistics\r\n",
        "\t# Whereas (Group 2003, Table 2) uses age intervals such as 20-30 years, 30-40 years, on the other\r\n",
        "\t# hand, (Ramakrishnan et al. 2019, Table 1) uses 45-55 years, 55-65 years as intervals instead\r\n",
        "\t\r\n",
        "\t# Genders are Female, Male -- these are indexed as Female = 0, Male = 1\r\n",
        "\t# The above convention is chosen to simplfy the susceptibility calculations\r\n",
        "\t# In all tables below, the first column is for the female gender and the second column for males\r\n",
        "\t@classmethod\r\n",
        "\tdef getDemographics( cls, N ):\r\n",
        "\t\t# Taken from (Ministry Home Affairs India 2016, Detailed Tables)\r\n",
        "\t\tageSplitbyGender = np.array([\r\n",
        "\t\t\t[ 0.363, 0.380 ],\r\n",
        "\t\t\t[ 0.205, 0.197 ],\r\n",
        "\t\t\t[ 0.152, 0.151 ],\r\n",
        "\t\t\t[ 0.061, 0.061 ],\r\n",
        "\t\t\t[ 0.054, 0.053 ],\r\n",
        "\t\t\t[ 0.043, 0.044 ],\r\n",
        "\t\t\t[ 0.037, 0.035 ],\r\n",
        "\t\t\t[ 0.031, 0.030 ],\r\n",
        "\t\t\t[ 0.022, 0.021 ],\r\n",
        "\t\t\t[ 0.015, 0.014 ],\r\n",
        "\t\t\t[ 0.009, 0.008 ], \r\n",
        "\t\t\t[ 0.008, 0.006 ]\r\n",
        "\t\t])\r\n",
        "\t\t\r\n",
        "\t\tcumSplitbyGender = np.cumsum( ageSplitbyGender, axis = 0 )\r\n",
        "\t\t\r\n",
        "\t\t# According to the 2011 census, India's gender ratio is 51.5% males to 48.5% females\r\n",
        "\t\tgenderSplit = 0.515\r\n",
        "\t\t\r\n",
        "\t\t# Taken from (Group 2003, Table 2)\r\n",
        "\t\tdiabetesSplit = np.array([\r\n",
        "\t\t\t[ 0.000, 0.000 ],\r\n",
        "\t\t\t[ 0.000, 0.000 ],\r\n",
        "\t\t\t[ 0.125, 0.114 ],\r\n",
        "\t\t\t[ 0.227, 0.218 ],\r\n",
        "\t\t\t[ 0.227, 0.218 ],\r\n",
        "\t\t\t[ 0.326, 0.330 ],\r\n",
        "\t\t\t[ 0.326, 0.330 ],\r\n",
        "\t\t\t[ 0.346, 0.410 ],\r\n",
        "\t\t\t[ 0.346, 0.410 ],\r\n",
        "\t\t\t[ 0.330, 0.326 ],\r\n",
        "\t\t\t[ 0.330, 0.326 ],\r\n",
        "\t\t\t[ 0.177, 0.242 ]\r\n",
        "\t\t])\r\n",
        "\t\t\r\n",
        "\t\t# Taken from (Ramakrishnan et al. 2019, Table 1)\r\n",
        "\t\thypertensionSplit = np.array([\r\n",
        "\t\t\t[ 0.062, 0.161 ],\r\n",
        "\t\t\t[ 0.140, 0.267 ],\r\n",
        "\t\t\t[ 0.140, 0.267 ],\r\n",
        "\t\t\t[ 0.140, 0.267 ],\r\n",
        "\t\t\t[ 0.346, 0.424 ],\r\n",
        "\t\t\t[ 0.346, 0.424 ],\r\n",
        "\t\t\t[ 0.454, 0.490 ],\r\n",
        "\t\t\t[ 0.454, 0.490 ],\r\n",
        "\t\t\t[ 0.514, 0.515 ],\r\n",
        "\t\t\t[ 0.514, 0.515 ],\r\n",
        "\t\t\t[ 0.513, 0.522 ],\r\n",
        "\t\t\t[ 0.513, 0.522 ],\r\n",
        "\t\t])\r\n",
        "\t\t\r\n",
        "\t\tdemoData = np.zeros( ( N, 5 ) )\r\n",
        "\t\t# Sample random numbers in bulk for speed\r\n",
        "\t\trandomCoins = np.random.uniform( 0, 1, ( N, 4 ) )\r\n",
        "\t\t\r\n",
        "\t\tIDX_AGE = 0\t\t# The age group of the person\r\n",
        "\t\tIDX_SEN = 1\t\t# The seniority of the person\r\n",
        "\t\tIDX_GEN = 2\t\t# The gender of the person\r\n",
        "\t\tIDX_DBT = 3\t\t# The diabetic status of the person\r\n",
        "\t\tIDX_HTN = 4\t\t# The hypertensive status of the person\r\n",
        "\t\t\r\n",
        "\t\t# TODO: The below for loop can surely be sped-up using vectorization/broadcasting techniques\r\n",
        "\t\tfor i in range( N ):\r\n",
        "\t\t\t# Since our primary data only gives us conditional statistics e.g. gender ratio, age split by gender\r\n",
        "\t\t\t# and not joint statistics, we should not sample individual attributes jointly but rather sequentially\r\n",
        "\t\t\t\r\n",
        "\t\t\tthisGender = 0\r\n",
        "\t\t\t# First sample the gender of the person\r\n",
        "\t\t\tif randomCoins[ i, 0 ] <= genderSplit:\r\n",
        "\t\t\t\tthisGender = 1\t\t\t\t\t\t\t# Its a boy!\r\n",
        "\t\t\tdemoData[ i, IDX_GEN ] = thisGender\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Next, sample the age-group of the person - use fresh randomness\r\n",
        "\t\t\tthisAgeGroup = np.digitize( randomCoins[ i, 1 ], cumSplitbyGender[ :, thisGender ], right = True )\r\n",
        "\t\t\tdemoData[ i, IDX_AGE ] = thisAgeGroup\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Next, decide the seniority of the person\r\n",
        "\t\t\tthisSeniority = 0\r\n",
        "\t\t\t# Persons above 55 years of age are classified as senior according to (Joshi 2020, Table 1)\r\n",
        "\t\t\tif thisAgeGroup > 5:\r\n",
        "\t\t\t\tthisSeniority = 1\r\n",
        "\t\t\tdemoData[ i, IDX_SEN ] = thisSeniority\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Next, decide the diabetic status of the person - use fresh randomness\r\n",
        "\t\t\tthisDiabetic = 0\r\n",
        "\t\t\tif randomCoins[ i, 2 ] <= diabetesSplit[ thisAgeGroup, thisGender ]:\r\n",
        "\t\t\t\tthisDiabetic = 1\r\n",
        "\t\t\tdemoData[ i, IDX_DBT ] = thisDiabetic\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Finally, decide the hypertensive status of the person - use fresh randomness\r\n",
        "\t\t\tthisHypertensive = 0\r\n",
        "\t\t\tif randomCoins[ i, 3 ] <= hypertensionSplit[ thisAgeGroup, thisGender ]:\r\n",
        "\t\t\t\tthisHypertensive = 1\r\n",
        "\t\t\tdemoData[ i, IDX_HTN ] = thisHypertensive\r\n",
        "\t\t\t\r\n",
        "\t\treturn demoData\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB9oG9icO595"
      },
      "source": [
        "## Inputs:\r\n",
        "\r\n",
        "n_start_AcqFunc = 100\r\n",
        "\r\n",
        "obj_func = 'Optimizing Lockdown'\r\n",
        "n_test = n_start_AcqFunc\r\n",
        "\r\n",
        "util_loser = 'dEI_GP'\r\n",
        "util_winner = 'EI_GP'\r\n",
        "n_init = 4"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmTRQrOAPQ5R"
      },
      "source": [
        "## Cumulative Regret Calculator:\r\n",
        "\r\n",
        "def min_max_array(x):\r\n",
        "  new_list = []\r\n",
        "  for i, num in enumerate(x):\r\n",
        "    new_list.append(np.min(x[0:i+1]))\r\n",
        "  return new_list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPWUiXbEPbxv"
      },
      "source": [
        "## Derivatives - Squared-exponential covariance function:\r\n",
        "\r\n",
        "def l2norm_(X, Xstar):\r\n",
        "    \r\n",
        "    return cdist(X, Xstar)\r\n",
        "\r\n",
        "def kronDelta(X, Xstar):\r\n",
        "\r\n",
        "    return cdist(X, Xstar) < np.finfo(np.float32).eps\r\n",
        "\r\n",
        "class squaredExponentialDeriv(squaredExponential):\r\n",
        "    l = 1\r\n",
        "    sigmaf = 1\r\n",
        "    sigman = 1e-6\r\n",
        "\r\n",
        "    def K(self, X, Xstar):\r\n",
        "        \r\n",
        "        r = (l2norm_(X, Xstar)/self.l)\r\n",
        "        K = self.sigmaf * np.exp(-1/2*r **2) + self.sigman * kronDelta(X, Xstar)\r\n",
        "        return K\r\n",
        "    \r\n",
        "    def dK(self, X, Xstar):\r\n",
        "        \r\n",
        "        r = (l2norm_(X, Xstar)/self.l)\r\n",
        "        dK = self.sigmaf/self.l**2 * np.exp(-1/2 * r **2) * l2norm_(X, Xstar)\r\n",
        "        return dK\r\n",
        "    \r\n",
        "    def d2K(self, X, Xstar):\r\n",
        "        \r\n",
        "        r = (l2norm_(X, Xstar)/self.l)\r\n",
        "        d2K = self.sigmaf/self.l**2 * np.exp(-1/2 * r **2) * (r **2 - 1)\r\n",
        "        return d2K\r\n",
        "    \r\n",
        "cov_func = squaredExponential()\r\n",
        "d_cov_func = squaredExponentialDeriv()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YwnaFDUQPXv"
      },
      "source": [
        "### Acquisition function derivatives:\r\n",
        "\r\n",
        "class Acquisition_new(Acquisition):    \r\n",
        "    def __init__(self, mode, eps=1e-08, **params):\r\n",
        "        \r\n",
        "        self.params = params\r\n",
        "        self.eps = eps\r\n",
        "\r\n",
        "        mode_dict = {\r\n",
        "            'EI_GP': self.EI_GP,\r\n",
        "            'dEI_GP': self.dEI_GP\r\n",
        "        }\r\n",
        "\r\n",
        "        self.f = mode_dict[mode]\r\n",
        "    \r\n",
        "    def EI_GP(self, tau, mean, std):\r\n",
        "        \r\n",
        "        z = -1 * (mean - tau - self.eps) / (std + self.eps)\r\n",
        "        return z * (std + self.eps) * norm.cdf(z) + (std + self.eps) * norm.pdf(z)[0]\r\n",
        "    \r\n",
        "    def dEI_GP(self, tau, mean, std, ds, dm, dvdv, d2v, d2m):\r\n",
        "        z = -1 * (mean - tau - self.eps) / (std + self.eps)\r\n",
        "        \r\n",
        "        dsdx = ds / 2 * (std + self.eps)\r\n",
        "        d2sdx = -dsdx**2 / ((std + self.eps)) - dvdv / (std + self.eps) - d2v / (std + self.eps)\r\n",
        "        dmdx = (dm - z * dsdx) / (std + self.eps)\r\n",
        "        d2mdx = (d2m - (z * d2sdx + 2 * dmdx * dsdx)) / (std + self.eps)\r\n",
        "        \r\n",
        "        f = (std + self.eps) * (z * norm.cdf(z) + norm.pdf(z)[0])\r\n",
        "        df = (f / (std + self.eps) * dsdx + (std + self.eps) * norm.cdf(z) * dmdx)\r\n",
        "        d2f = (f / (std + self.eps) * d2sdx + dsdx * dmdx * norm.cdf(z) \\\r\n",
        "            + d2mdx * (std + self.eps) * norm.cdf(z) + dsdx * norm.cdf(z) * dmdx \\\r\n",
        "            + norm.pdf(z)[0] * (std + self.eps) * dmdx)\r\n",
        "            \r\n",
        "        return f, df, d2f\r\n",
        "    \r\n",
        "    def _eval(self, tau, mean, std):\r\n",
        "    \r\n",
        "        return self.f(tau, mean, std, **self.params)\r\n",
        "    \r\n",
        "    def d_eval(self, tau, mean, std, ds, dm, dvdv, d2v, d2m):\r\n",
        "    \r\n",
        "        return self.f(tau, mean, std, ds, dm, dvdv, d2v, d2m, **self.params)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWiJocDIUTBa"
      },
      "source": [
        "### Surrogate derivatives: \r\n",
        "\r\n",
        "from scipy.linalg import cholesky, solve\r\n",
        "\r\n",
        "class dGaussianProcess(GaussianProcess):\r\n",
        "    l = 1\r\n",
        "    sigmaf = 1\r\n",
        "    sigman = 1e-6\r\n",
        "\r\n",
        "    def AcqGrad(self, Xstar, return_std=False):\r\n",
        "        r_X = l2norm_(self.X, self.X)/self.l\r\n",
        "        K = self.sigmaf * np.exp(-1/2*r_X **2) + self.sigman * kronDelta(self.X, self.X)\r\n",
        "        L = cholesky(K).T\r\n",
        "        alpha = solve(L.T, solve(L, self.y))\r\n",
        "        Xstar = np.atleast_2d(Xstar)\r\n",
        "        Kstar = squaredExponentialDeriv.K(self, self.X, Xstar).T\r\n",
        "        dKstar = squaredExponentialDeriv.dK(self, self.X, Xstar).T\r\n",
        "        d2Kstar = squaredExponentialDeriv.d2K(self, self.X, Xstar).T\r\n",
        "        v = solve(self.L, Kstar.T)\r\n",
        "        dv = solve(self.L, dKstar.T)\r\n",
        "        d2v = solve(self.L, d2Kstar.T)\r\n",
        "        \r\n",
        "        ds = -2 * np.dot(dv.T, v)\r\n",
        "        dvdv = np.dot(dv.T, dv)\r\n",
        "        d2s = -2 * (dvdv + d2v)\r\n",
        "        \r\n",
        "        dm = np.dot(dKstar, alpha)\r\n",
        "        d2m = np.dot(d2Kstar, alpha)\r\n",
        "        return ds, dm, dvdv, d2v, d2m"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV2Zg7B9U_YT"
      },
      "source": [
        "### d2GPGO - BayesOpt class: Exact Hessian\r\n",
        "\r\n",
        "class d2GPGO(GPGO):  \r\n",
        "    n_start = n_start_AcqFunc\r\n",
        "    p = np.full((n_start,1),1)*0 + 1\r\n",
        "    eps = 1e-08\r\n",
        "    \r\n",
        "    def func(self, xnew):\r\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\r\n",
        "        new_std = np.sqrt(new_var + 1e-6)\r\n",
        "        ds, dm, dvdv, d2v, d2m = self.GP.AcqGrad(xnew, return_std=True)\r\n",
        "        f  = np.empty((self.n_start,))\r\n",
        "        df = np.empty((self.n_start,))\r\n",
        "        f  = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2v=d2v, d2m=d2m)[0]\r\n",
        "        df = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2v=d2v, d2m=d2m)[1]\r\n",
        "        df_array = np.full((len(xnew),),df)\r\n",
        "        return f, df_array\r\n",
        "    \r\n",
        "    def hessp_nonzero(self, xnew, p):\r\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\r\n",
        "        new_std = np.sqrt(new_var + 1e-6)\r\n",
        "        ds, dm, dvdv, d2v, d2m = self.GP.AcqGrad(xnew, return_std=True)\r\n",
        "        df2 = np.empty((self.n_start,))\r\n",
        "        df2 = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2v=d2v, d2m=d2m)[2]\r\n",
        "        H2 = np.empty((self.n_start,))\r\n",
        "        df2 = np.asarray(df2)\r\n",
        "        p = np.asarray(p)\r\n",
        "        H2 = np.multiply(df2,p)\r\n",
        "        return H2\r\n",
        "\r\n",
        "    def dEI_GP(self, tau, mean, std, ds, dm, dvdv, d2v, d2m):\r\n",
        "        z = -1 * (tau - mean - self.eps) / (std + self.eps)\r\n",
        "        \r\n",
        "        dsdx = ds / 2 * (std + self.eps)\r\n",
        "        d2sdx = -dsdx**2 / ((std + self.eps)) - dvdv / (std + self.eps) - d2v / (std + self.eps)\r\n",
        "        dmdx = (dm - z * dsdx) / (std + self.eps)\r\n",
        "        d2mdx = (d2m - (z * d2sdx + 2 * dmdx * dsdx)) / (std + self.eps)\r\n",
        "        \r\n",
        "        d2f = (z * norm.cdf(z) + norm.pdf(z)[0]) * d2sdx + dsdx * dmdx * norm.cdf(z) \\\r\n",
        "            + d2mdx * (std + self.eps) * norm.cdf(z) + dsdx * norm.cdf(z) * dmdx \\\r\n",
        "            + norm.pdf(z)[0] * (std + self.eps) * dmdx\r\n",
        "\r\n",
        "        return d2f\r\n",
        "\r\n",
        "    def hessp_nonzero1(self, xnew, p, *args):\r\n",
        "      new_mean, new_var = self.GP.predict(xnew, return_std=True)\r\n",
        "      new_std = np.sqrt(new_var + 1e-6)\r\n",
        "      ds, dm, dvdv, d2v, d2m = self.GP.AcqGrad(xnew, return_std=True)\r\n",
        "      df2 = np.empty((self.n_start,))\r\n",
        "      df2 = -self.dEI_GP(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2v=d2v, d2m=d2m)[0] * p\r\n",
        "      return df2\r\n",
        "\r\n",
        "    def d_optimizeAcq(self, method='Newton-CG', n_start=n_start):\r\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\r\n",
        "        start_points_arr = np.array([list(s.values())\r\n",
        "                                     for s in start_points_dict])\r\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\r\n",
        "        f_best = np.empty((n_start,))\r\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.func,\r\n",
        "                                                                 x0=start_point,\r\n",
        "                                                                 method=method,\r\n",
        "                                                                 jac = True,                  \r\n",
        "                                                                 hessp = self.hessp_nonzero1,                      \r\n",
        "                                                                 bounds=self.parameter_range) for start_point in\r\n",
        "                                               start_points_arr)\r\n",
        "        \r\n",
        "        x_best = np.array([res.x for res in opt])\r\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\r\n",
        "\r\n",
        "        self.x_best = x_best\r\n",
        "        self.f_best = f_best\r\n",
        "        self.best = x_best[np.argmin(f_best)]\r\n",
        "\r\n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):    \r\n",
        "        if not resume:\r\n",
        "            self.init_evals = init_evals\r\n",
        "            self._firstRun(self.init_evals)\r\n",
        "            self.logger._printInit(self)\r\n",
        "        for iteration in range(max_iter):\r\n",
        "            self.d_optimizeAcq()\r\n",
        "            #self.updateGP()\r\n",
        "            self.updateGP_min()\r\n",
        "            self.logger._printCurrent(self)\r\n",
        "\r\n",
        "    def updateGP_min(self):\r\n",
        "\r\n",
        "        kw = {param: self.best[i]\r\n",
        "              for i, param in enumerate(self.parameter_key)}\r\n",
        "        f_new = self.f(**kw)\r\n",
        "        self.GP.update(np.atleast_2d(self.best), np.atleast_1d(f_new))\r\n",
        "        self.tau = np.min(self.GP.y)\r\n",
        "        self.history.append(self.tau)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH1y-f17VGEu"
      },
      "source": [
        "class GPGO_min(GPGO):\r\n",
        "\r\n",
        "  def updateGP(self):\r\n",
        "\r\n",
        "        kw = {param: self.best[i]\r\n",
        "              for i, param in enumerate(self.parameter_key)}\r\n",
        "        f_new = self.f(**kw)\r\n",
        "        self.GP.update(np.atleast_2d(self.best), np.atleast_1d(f_new))\r\n",
        "        self.tau = np.min(self.GP.y)\r\n",
        "        self.history.append(self.tau)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8-7_K9cVCis",
        "outputId": "83882309-ab83-4c0a-8ae9-a5cdb40f748f"
      },
      "source": [
        "start_lose = time.time()\r\n",
        "start_lose"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1616071926.922521"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Llhv7cLGpw7H",
        "outputId": "066f401c-883e-4f33-8894-7e5190a719ba"
      },
      "source": [
        "## url = 'https://github.com/purushottamkar/esop/blob/master/pop_generic'\r\n",
        "\r\n",
        "from google.colab import files #pop_generic file is saved to the same Google Colab folder as this workbook\r\n",
        "uploaded = files.upload()\r\n",
        "\r\n",
        "## Defines new data object as pop_generic"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-34d52a3a-4076-4399-974d-0433591b6995\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-34d52a3a-4076-4399-974d-0433591b6995\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving pop_generic to pop_generic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt7XzVypVHmy"
      },
      "source": [
        "### Objective Function\r\n",
        "\r\n",
        "if obj_func == 'Optimizing Lockdown':\r\n",
        "\r\n",
        "  # Constraints:\r\n",
        "  param_lb_uniform = 0\r\n",
        "  param_ub_uniform = 1\r\n",
        "\r\n",
        "  # 1-D inputs' parameter bounds:\r\n",
        "  param = {'x': ('cont', (param_lb_uniform, param_ub_uniform))}\r\n",
        "\r\n",
        "  pop = Population.fileInit(\"pop_generic\")\r\n",
        "  pop.INC = 10\r\n",
        "  N = pop.N\r\n",
        "  T = 500\r\n",
        "  P0 = 30\r\n",
        "  L0 = 5\r\n",
        "\r\n",
        "  SIDX_S = 0  # Number of individuals: susceptible & non-recovered\r\n",
        "  SIDX_E = 1  # Number of individuals: exposed\r\n",
        "  SIDX_I = 2  # Number of individuals: infectious\r\n",
        "  SIDX_Q = 3  # Number of individuals: quarantined\r\n",
        "  SIDX_R = 4  # Number of individuals: recovered\r\n",
        "  SIDX_X = 5  # Number of individuals: expired\r\n",
        "  SIDX_V = 6  # Average virulence of viral strains\r\n",
        "  SIDX_EI = 7 # Number of individuals: infected\r\n",
        "  SIDX_D = 8  # Number of individuals: daily infections\r\n",
        "\r\n",
        "  I0c = 50\r\n",
        "  I0w = 50\r\n",
        "  evalCount = 0\r\n",
        "  globalDict = {}\r\n",
        "  freshMask = []\r\n",
        "  # Upper and lower bounds on legal values of lock-down intialization points:\r\n",
        "  ul = 100\r\n",
        "  ll = 0\r\n",
        "\r\n",
        "  def getI0( x ): \r\n",
        "    global I0c, I0w, ul, ll\r\n",
        "    SVal = int( np.floor( I0c + (x - 0.5) / 0.5 * I0w ) )\r\n",
        "    # Make sure that the recovered value is a legal one\r\n",
        "    correctedSVal = min( max( SVal, ll ), ul )\r\n",
        "    return correctedSVal\r\n",
        "\r\n",
        "  # Get a lockdown schedule corresponding to a certain I0 value\r\n",
        "  def getLKP( I0 ):\r\n",
        "    LKP = np.zeros((T,))\r\n",
        "    LKP[I0:I0+P0] = L0\r\n",
        "    return LKP\r\n",
        "\r\n",
        "  # Find out the objective value corresponding to the stats sent as input\r\n",
        "  # For this experiment, the objective value is simply f_epi since f_eco is\r\n",
        "  # already decided since the duration of the lock-down is fixed at P0 = 30\r\n",
        "  def obj( stats ):\r\n",
        "    global SIDX_EI\r\n",
        "    fEpi = np.max( stats[ SIDX_EI, : ] )\r\n",
        "    return fEpi\r\n",
        "\r\n",
        "  # Ask the VIPER simulator what does it think will happen if lock-down is\r\n",
        "  # initiated as specified in the normalized parameter x\r\n",
        "  def f_syn_polarity( x ):\r\n",
        "    global I0c, I0w, evalCount, globalDict, freshMask\r\n",
        "    # Before starting a simulation, turn back time to reset everything\r\n",
        "    pop.reset()\r\n",
        "    # Replicable simulations\r\n",
        "    np.random.seed(0)\r\n",
        "    I0 = getI0(x)\r\n",
        "    # Avoid re-sampling the same points\r\n",
        "    #if I0 in globalDict:\r\n",
        "    #  freshMask.append(False)\r\n",
        "    #  return globalDict[I0]\r\n",
        "    LKP = getLKP( I0 )\r\n",
        "    stats = pop.simulate( T = T, LKP = LKP, minimal = True )\r\n",
        "    globalDict[I0] = obj( stats )\r\n",
        "    freshMask.append( True )\r\n",
        "    evalCount += 1\r\n",
        "    return obj( stats )\r\n",
        "\r\n",
        "  # Once ESOP is done, find out which parameter, i.e. which value of I0 won!\r\n",
        "  def getWinner():\r\n",
        "    global globalDict\r\n",
        "    keys = np.array( list( globalDict.keys() ) )\r\n",
        "    vals = np.array( list( globalDict.values() ) )\r\n",
        "    winnerIdx = np.argmin( vals )\r\n",
        "    winner = keys[ winnerIdx ]\r\n",
        "    return winner\r\n",
        "\r\n",
        "  max_iter = 10"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULjUdz_VVMhi"
      },
      "source": [
        "### Set-seeds:\r\n",
        "\r\n",
        "run_num_1 = 1\r\n",
        "run_num_2 = 2\r\n",
        "run_num_3 = 3333\r\n",
        "run_num_4 = 4\r\n",
        "run_num_5 = 555\r\n",
        "run_num_6 = 6\r\n",
        "run_num_7 = 7\r\n",
        "run_num_8 = 88\r\n",
        "run_num_9 = 99999\r\n",
        "run_num_10 = 1000\r\n",
        "run_num_11 = 11\r\n",
        "run_num_12 = 1222\r\n",
        "run_num_13 = 13\r\n",
        "run_num_14 = 14\r\n",
        "run_num_15 = 155\r\n",
        "run_num_16 = 1667\r\n",
        "run_num_17 = 1777\r\n",
        "run_num_18 = 188\r\n",
        "run_num_19 = 19\r\n",
        "run_num_20 = 20\r\n",
        "\r\n",
        "y_global_orig = 0"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D17KR38gYRE6",
        "outputId": "5dc3f258-9810-40e1-aff0-ea1c3d5ccb82"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 1\r\n",
        "\r\n",
        "np.random.seed(run_num_1)\r\n",
        "surrogate_loser_1 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_1 = d2GPGO(surrogate_loser_1, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_1.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.417022]. \t  11254.0 \t 12696.0\n",
            "init   \t [0.68467162]. \t  8453.0 \t 12696.0\n",
            "init   \t [0.24385644]. \t  12696.0 \t 12696.0\n",
            "init   \t [0.52583438]. \t  9416.0 \t 12696.0\n",
            "1      \t [0.67289702]. \t  \u001b[92m8173.0\u001b[0m \t 8173.0\n",
            "2      \t [0.00847621]. \t  \u001b[92m13577.0\u001b[0m \t 8173.0\n",
            "3      \t [0.73759115]. \t  \u001b[92m9869.0\u001b[0m \t 8173.0\n",
            "4      \t [0.11344079]. \t  \u001b[92m13409.0\u001b[0m \t 8173.0\n",
            "5      \t [0.34658064]. \t  \u001b[92m12158.0\u001b[0m \t 8173.0\n",
            "6      \t [0.25357886]. \t  \u001b[92m12681.0\u001b[0m \t 8173.0\n",
            "7      \t [0.262744]. \t  \u001b[92m12765.0\u001b[0m \t 8173.0\n",
            "8      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "9      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "10     \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrYi8mQSwUaj",
        "outputId": "a45fe872-276c-4b65-b2fc-6d91af603e45"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 2\r\n",
        "\r\n",
        "np.random.seed(run_num_2)\r\n",
        "surrogate_loser_2 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_2 = d2GPGO(surrogate_loser_2, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_2.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.4359949]. \t  11013.0 \t 13577.0\n",
            "init   \t [0.27990374]. \t  12840.0 \t 13577.0\n",
            "init   \t [0.74772621]. \t  10110.0 \t 13577.0\n",
            "init   \t [0.007856]. \t  13577.0 \t 13577.0\n",
            "1      \t [0.62355804]. \t  \u001b[92m6672.0\u001b[0m \t 6672.0\n",
            "2      \t [0.09102036]. \t  \u001b[92m13585.0\u001b[0m \t 6672.0\n",
            "3      \t [0.40764505]. \t  \u001b[92m11522.0\u001b[0m \t 6672.0\n",
            "4      \t [0.26268]. \t  \u001b[92m12765.0\u001b[0m \t 6672.0\n",
            "5      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6672.0\n",
            "6      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6672.0\n",
            "7      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6672.0\n",
            "8      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6672.0\n",
            "9      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 6672.0\n",
            "10     \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 6672.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NsIJB6Bws4q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3077ee1c-0969-40f3-b4cb-d8caf34865b0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 3\r\n",
        "\r\n",
        "np.random.seed(run_num_3)\r\n",
        "surrogate_loser_3 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_3 = d2GPGO(surrogate_loser_3, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_3.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.75157561]. \t  10387.0 \t 14019.0\n",
            "init   \t [0.98028867]. \t  14019.0 \t 14019.0\n",
            "init   \t [0.51198591]. \t  9464.0 \t 14019.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 14019.0\n",
            "1      \t [0.5561781]. \t  \u001b[92m8554.0\u001b[0m \t 8554.0\n",
            "2      \t [0.44732037]. \t  \u001b[92m10874.0\u001b[0m \t 8554.0\n",
            "3      \t [0.19297376]. \t  \u001b[92m13101.0\u001b[0m \t 8554.0\n",
            "4      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 8554.0\n",
            "5      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 8554.0\n",
            "6      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 8554.0\n",
            "7      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 8554.0\n",
            "8      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 8554.0\n",
            "9      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 8554.0\n",
            "10     \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 8554.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AW-ZhjzxC7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "807b1463-08c5-4bcc-f7f9-3db470326f54"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 4\r\n",
        "\r\n",
        "np.random.seed(run_num_4)\r\n",
        "surrogate_loser_4 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_4 = d2GPGO(surrogate_loser_4, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_4.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.96702984]. \t  13962.0 \t 14019.0\n",
            "init   \t [0.88857941]. \t  13154.0 \t 14019.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 14019.0\n",
            "init   \t [0.98028867]. \t  14019.0 \t 14019.0\n",
            "1      \t [0.00949436]. \t  \u001b[92m13577.0\u001b[0m \t 10387.0\n",
            "2      \t [0.36474576]. \t  \u001b[92m12051.0\u001b[0m \t 10387.0\n",
            "3      \t [0.58873335]. \t  \u001b[92m7940.0\u001b[0m \t 7940.0\n",
            "4      \t [0.90925644]. \t  \u001b[92m13431.0\u001b[0m \t 7940.0\n",
            "5      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7940.0\n",
            "6      \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7940.0\n",
            "7      \t [0.26221209]. \t  \u001b[92m12765.0\u001b[0m \t 7940.0\n",
            "8      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "9      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "10     \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_362CbCxTja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee84754-e93e-4a4b-ae77-a8922169d62e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 5\r\n",
        "\r\n",
        "np.random.seed(run_num_5)\r\n",
        "surrogate_loser_5 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_5 = d2GPGO(surrogate_loser_5, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_5.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.71783409]. \t  9343.0 \t 13169.0\n",
            "init   \t [0.21573829]. \t  13169.0 \t 13169.0\n",
            "init   \t [0.88513393]. \t  13154.0 \t 13169.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 13169.0\n",
            "1      \t [0.50046669]. \t  \u001b[92m9472.0\u001b[0m \t 9343.0\n",
            "2      \t [0.60739275]. \t  \u001b[92m7178.0\u001b[0m \t 7178.0\n",
            "3      \t [0.56613346]. \t  \u001b[92m7747.0\u001b[0m \t 7178.0\n",
            "4      \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 7178.0\n",
            "5      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 7178.0\n",
            "6      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 7178.0\n",
            "7      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 7178.0\n",
            "8      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 7178.0\n",
            "9      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7178.0\n",
            "10     \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7178.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq1gQLFgxbhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72228f80-1887-4c09-875a-57e234639f53"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 6\r\n",
        "\r\n",
        "np.random.seed(run_num_6)\r\n",
        "surrogate_loser_6 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_6 = d2GPGO(surrogate_loser_6, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_6.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.89286015]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "init   \t [0.26221209]. \t  12765.0 \t 13914.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13914.0\n",
            "1      \t [0.50038269]. \t  \u001b[92m9472.0\u001b[0m \t 6992.0\n",
            "2      \t [0.00757141]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "3      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "4      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "5      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "6      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "7      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blHM3jnYxpVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59e77105-d89a-4ba0-a2f2-a47e51c79737"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 7\r\n",
        "\r\n",
        "np.random.seed(run_num_7)\r\n",
        "surrogate_loser_7 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_7 = d2GPGO(surrogate_loser_7, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_7.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.07630829]. \t  13442.0 \t 13503.0\n",
            "init   \t [0.3076631]. \t  12533.0 \t 13503.0\n",
            "init   \t [0.06469076]. \t  13503.0 \t 13503.0\n",
            "init   \t [0.51622115]. \t  9464.0 \t 13503.0\n",
            "1      \t [0.98036145]. \t  \u001b[92m14019.0\u001b[0m \t 9464.0\n",
            "2      \t [0.68720353]. \t  \u001b[92m8453.0\u001b[0m \t 8453.0\n",
            "3      \t [0.67392032]. \t  \u001b[92m8173.0\u001b[0m \t 8173.0\n",
            "4      \t [0.87162387]. \t  \u001b[92m13019.0\u001b[0m \t 8173.0\n",
            "5      \t [0.00538944]. \t  \u001b[92m13577.0\u001b[0m \t 8173.0\n",
            "6      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 8173.0\n",
            "7      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 8173.0\n",
            "8      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 8173.0\n",
            "9      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 8173.0\n",
            "10     \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 8173.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV5G9m-5x2Br",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beb7efd5-f018-4099-f292-ace8122c62aa"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 8\r\n",
        "\r\n",
        "np.random.seed(run_num_8)\r\n",
        "surrogate_loser_8 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_8 = d2GPGO(surrogate_loser_8, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_8.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.64755105]. \t  7277.0 \t 13962.0\n",
            "init   \t [0.93600076]. \t  13728.0 \t 13962.0\n",
            "init   \t [0.96051377]. \t  13962.0 \t 13962.0\n",
            "init   \t [0.88857941]. \t  13154.0 \t 13962.0\n",
            "1      \t [0.01382912]. \t  \u001b[92m13603.0\u001b[0m \t 7277.0\n",
            "2      \t [0.37401417]. \t  \u001b[92m11677.0\u001b[0m \t 7277.0\n",
            "3      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7277.0\n",
            "4      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7277.0\n",
            "5      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7277.0\n",
            "6      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7277.0\n",
            "7      \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7277.0\n",
            "8      \t [0.26221209]. \t  \u001b[92m12765.0\u001b[0m \t 7277.0\n",
            "9      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "10     \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18hoXfzQzcF6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48f5dec-2176-4e9c-e24a-312fa0fed6ec"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 9\r\n",
        "\r\n",
        "np.random.seed(run_num_9)\r\n",
        "surrogate_loser_9 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_9 = d2GPGO(surrogate_loser_9, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_9.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.20706637]. \t  13263.0 \t 13685.0\n",
            "init   \t [0.72910832]. \t  9585.0 \t 13685.0\n",
            "init   \t [0.80093216]. \t  11701.0 \t 13685.0\n",
            "init   \t [0.04439363]. \t  13685.0 \t 13685.0\n",
            "1      \t [0.59904747]. \t  \u001b[92m7210.0\u001b[0m \t 7210.0\n",
            "2      \t [0.47931887]. \t  \u001b[92m10418.0\u001b[0m \t 7210.0\n",
            "3      \t [0.90715029]. \t  \u001b[92m13431.0\u001b[0m \t 7210.0\n",
            "4      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7210.0\n",
            "5      \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7210.0\n",
            "6      \t [0.26221209]. \t  \u001b[92m12765.0\u001b[0m \t 7210.0\n",
            "7      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "8      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "9      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n",
            "10     \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wrqaX_EzcXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5acd8ef1-775f-40e7-f164-5d703c93eb05"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 10\r\n",
        "\r\n",
        "np.random.seed(run_num_10)\r\n",
        "surrogate_loser_10 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_10 = d2GPGO(surrogate_loser_10, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_10.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.65358959]. \t  7572.0 \t 13656.0\n",
            "init   \t [0.42232996]. \t  11151.0 \t 13656.0\n",
            "init   \t [0.05316146]. \t  13656.0 \t 13656.0\n",
            "init   \t [0.00983665]. \t  13577.0 \t 13656.0\n",
            "1      \t [0.9795807]. \t  \u001b[92m13990.0\u001b[0m \t 7572.0\n",
            "2      \t [0.71272955]. \t  \u001b[92m9343.0\u001b[0m \t 7572.0\n",
            "3      \t [0.21573829]. \t  \u001b[92m13169.0\u001b[0m \t 7572.0\n",
            "4      \t [0.88513393]. \t  \u001b[92m13154.0\u001b[0m \t 7572.0\n",
            "5      \t [0.75514332]. \t  \u001b[92m10387.0\u001b[0m \t 7572.0\n",
            "6      \t [0.98028867]. \t  \u001b[92m14019.0\u001b[0m \t 7572.0\n",
            "7      \t [0.51198591]. \t  \u001b[92m9464.0\u001b[0m \t 7572.0\n",
            "8      \t [0.0813946]. \t  \u001b[92m13505.0\u001b[0m \t 7572.0\n",
            "9      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 7572.0\n",
            "10     \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soFmsoi9zcdB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b043bbf-6680-434f-8628-c389c6d43808"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 11\r\n",
        "\r\n",
        "np.random.seed(run_num_11)\r\n",
        "surrogate_loser_11 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_11 = d2GPGO(surrogate_loser_11, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_11.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.18026969]. \t  13281.0 \t 13281.0\n",
            "init   \t [0.61298159]. \t  7424.0 \t 13281.0\n",
            "init   \t [0.29368678]. \t  12546.0 \t 13281.0\n",
            "init   \t [0.29132308]. \t  12546.0 \t 13281.0\n",
            "1      \t [0.99379924]. \t  \u001b[92m14063.0\u001b[0m \t 7424.0\n",
            "2      \t [0.70345528]. \t  \u001b[92m9060.0\u001b[0m \t 7424.0\n",
            "3      \t [0.0740075]. \t  \u001b[92m13442.0\u001b[0m \t 7424.0\n",
            "4      \t [0.3076631]. \t  \u001b[92m12533.0\u001b[0m \t 7424.0\n",
            "5      \t [0.06469076]. \t  \u001b[92m13503.0\u001b[0m \t 7424.0\n",
            "6      \t [0.51622115]. \t  \u001b[92m9464.0\u001b[0m \t 7424.0\n",
            "7      \t [0.0813946]. \t  \u001b[92m13505.0\u001b[0m \t 7424.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 7424.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7424.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 7424.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CONGlWtUzciA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a0fdab-674b-49e2-8feb-02db75b034e5"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 12\r\n",
        "\r\n",
        "np.random.seed(run_num_12)\r\n",
        "surrogate_loser_12 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_12 = d2GPGO(surrogate_loser_12, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_12.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.06748528]. \t  13503.0 \t 13505.0\n",
            "init   \t [0.51622115]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "1      \t [0.99080111]. \t  \u001b[92m14063.0\u001b[0m \t 9464.0\n",
            "2      \t [0.70345528]. \t  \u001b[92m9060.0\u001b[0m \t 9060.0\n",
            "3      \t [0.65817875]. \t  \u001b[92m7572.0\u001b[0m \t 7572.0\n",
            "4      \t [0.42232996]. \t  \u001b[92m11151.0\u001b[0m \t 7572.0\n",
            "5      \t [0.05316146]. \t  \u001b[92m13656.0\u001b[0m \t 7572.0\n",
            "6      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7572.0\n",
            "7      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7572.0\n",
            "8      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 7572.0\n",
            "9      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 7572.0\n",
            "10     \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR9WC6s8zcm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca869b7f-d4cb-483a-b6d2-d06872d2dbd8"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 13\r\n",
        "\r\n",
        "np.random.seed(run_num_13)\r\n",
        "surrogate_loser_13 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_13 = d2GPGO(surrogate_loser_13, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_13.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.77770241]. \t  10939.0 \t 13619.0\n",
            "init   \t [0.92603084]. \t  13619.0 \t 13619.0\n",
            "init   \t [0.88451529]. \t  13154.0 \t 13619.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 13619.0\n",
            "1      \t [0.00250195]. \t  \u001b[92m13577.0\u001b[0m \t 10387.0\n",
            "2      \t [0.36474576]. \t  \u001b[92m12051.0\u001b[0m \t 10387.0\n",
            "3      \t [0.62660258]. \t  \u001b[92m6672.0\u001b[0m \t 6672.0\n",
            "4      \t [0.09102036]. \t  \u001b[92m13585.0\u001b[0m \t 6672.0\n",
            "5      \t [0.40764505]. \t  \u001b[92m11522.0\u001b[0m \t 6672.0\n",
            "6      \t [0.26268]. \t  \u001b[92m12765.0\u001b[0m \t 6672.0\n",
            "7      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6672.0\n",
            "8      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6672.0\n",
            "9      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6672.0\n",
            "10     \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6672.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDfu9f9PzcsN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edc64854-ed46-4c0f-82de-9cbf4a5900b6"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 14\r\n",
        "\r\n",
        "np.random.seed(run_num_14)\r\n",
        "surrogate_loser_14 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_14 = d2GPGO(surrogate_loser_14, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_14.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.51394334]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [0.98091914]. \t  \u001b[92m14019.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72476009]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rxpin3Fzcxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "654f7632-5373-43f7-d1ce-922a35f8b864"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 15\r\n",
        "\r\n",
        "np.random.seed(run_num_15)\r\n",
        "surrogate_loser_15 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_15 = d2GPGO(surrogate_loser_15, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_15.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.65232633]. \t  7572.0 \t 13656.0\n",
            "init   \t [0.42232996]. \t  11151.0 \t 13656.0\n",
            "init   \t [0.05316146]. \t  13656.0 \t 13656.0\n",
            "init   \t [0.00983665]. \t  13577.0 \t 13656.0\n",
            "1      \t [0.9795807]. \t  \u001b[92m13990.0\u001b[0m \t 7572.0\n",
            "2      \t [0.71272955]. \t  \u001b[92m9343.0\u001b[0m \t 7572.0\n",
            "3      \t [0.21573829]. \t  \u001b[92m13169.0\u001b[0m \t 7572.0\n",
            "4      \t [0.88513393]. \t  \u001b[92m13154.0\u001b[0m \t 7572.0\n",
            "5      \t [0.75514332]. \t  \u001b[92m10387.0\u001b[0m \t 7572.0\n",
            "6      \t [0.98028867]. \t  \u001b[92m14019.0\u001b[0m \t 7572.0\n",
            "7      \t [0.51198591]. \t  \u001b[92m9464.0\u001b[0m \t 7572.0\n",
            "8      \t [0.0813946]. \t  \u001b[92m13505.0\u001b[0m \t 7572.0\n",
            "9      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 7572.0\n",
            "10     \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXp3WoVTzc22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6717c104-5181-472d-c56f-49996d296b51"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 16\r\n",
        "\r\n",
        "np.random.seed(run_num_16)\r\n",
        "surrogate_loser_16 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_16 = d2GPGO(surrogate_loser_16, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_16.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.89472424]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "init   \t [0.26221209]. \t  12765.0 \t 13914.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13914.0\n",
            "1      \t [0.50038269]. \t  \u001b[92m9472.0\u001b[0m \t 6992.0\n",
            "2      \t [0.00757141]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "3      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "4      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "5      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "6      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "7      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGQANct4zc8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e9bda0a-fbdc-43fc-a6d7-e7e3fade2134"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 17\r\n",
        "\r\n",
        "np.random.seed(run_num_17)\r\n",
        "surrogate_loser_17 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_17 = d2GPGO(surrogate_loser_17, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_17.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.03062042]. \t  13305.0 \t 13505.0\n",
            "init   \t [0.08122315]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [0.98091914]. \t  \u001b[92m14019.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72476009]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tJrFjh5zdDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ee0dfd3-8acc-43ec-8928-690e3ff76d8d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 18\r\n",
        "\r\n",
        "np.random.seed(run_num_18)\r\n",
        "surrogate_loser_18 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_18 = d2GPGO(surrogate_loser_18, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_18.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.51197762]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [0.98091914]. \t  \u001b[92m14019.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72476009]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2cJMYL8zdMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a596f1b-b008-4a7b-a38f-c9ec2ff53e09"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 19\r\n",
        "\r\n",
        "np.random.seed(run_num_19)\r\n",
        "surrogate_loser_19 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_19 = d2GPGO(surrogate_loser_19, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_19.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.0975336]. \t  13585.0 \t 13585.0\n",
            "init   \t [0.40764505]. \t  11522.0 \t 13585.0\n",
            "init   \t [0.26268]. \t  12765.0 \t 13585.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13585.0\n",
            "1      \t [0.9950895]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "2      \t [0.74013984]. \t  \u001b[92m10110.0\u001b[0m \t 6992.0\n",
            "3      \t [0.007856]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "4      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "5      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "6      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "7      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "8      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "9      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "10     \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0JmbY_6zdTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "912fea65-82aa-4319-ed82-f9a424e1d33c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 20\r\n",
        "\r\n",
        "np.random.seed(run_num_20)\r\n",
        "surrogate_loser_20 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_20 = d2GPGO(surrogate_loser_20, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_20.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.5881308]. \t  7940.0 \t 13914.0\n",
            "init   \t [0.90925644]. \t  13431.0 \t 13914.0\n",
            "init   \t [0.89555325]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "1      \t [0.00214044]. \t  \u001b[92m13577.0\u001b[0m \t 7940.0\n",
            "2      \t [0.36474576]. \t  \u001b[92m12051.0\u001b[0m \t 7940.0\n",
            "3      \t [0.1964637]. \t  \u001b[92m13101.0\u001b[0m \t 7940.0\n",
            "4      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 7940.0\n",
            "5      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 7940.0\n",
            "6      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 7940.0\n",
            "7      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 7940.0\n",
            "8      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7940.0\n",
            "9      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7940.0\n",
            "10     \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 7940.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se976GulzdZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3cd2d7-20b6-4626-b748-ab7da270cbf9"
      },
      "source": [
        "end_lose = time.time()\r\n",
        "end_lose\r\n",
        "\r\n",
        "time_lose = end_lose - start_lose\r\n",
        "time_lose\r\n",
        "\r\n",
        "start_win = time.time()\r\n",
        "start_win"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1616073356.9018886"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEx2XiTi13jM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53eab2b9-f236-4fa7-8952-fe9157a5ca09"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 1 \r\n",
        "\r\n",
        "np.random.seed(run_num_1)\r\n",
        "surrogate_winner_1 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_1 = GPGO_min(surrogate_winner_1, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_1.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.417022]. \t  11254.0 \t 12696.0\n",
            "init   \t [0.68467162]. \t  8453.0 \t 12696.0\n",
            "init   \t [0.24385644]. \t  12696.0 \t 12696.0\n",
            "init   \t [0.52583438]. \t  9416.0 \t 12696.0\n",
            "1      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 8453.0\n",
            "2      \t [0.73022595]. \t  \u001b[92m9869.0\u001b[0m \t 8453.0\n",
            "3      \t [0.11344079]. \t  \u001b[92m13409.0\u001b[0m \t 8453.0\n",
            "4      \t [0.34658064]. \t  \u001b[92m12158.0\u001b[0m \t 8453.0\n",
            "5      \t [0.25357886]. \t  \u001b[92m12681.0\u001b[0m \t 8453.0\n",
            "6      \t [0.262744]. \t  \u001b[92m12765.0\u001b[0m \t 8453.0\n",
            "7      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "8      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "9      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n",
            "10     \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zugirIgK14Oy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a05347b2-afbc-42cb-85c7-3a1ed08cc88a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 2 \r\n",
        "\r\n",
        "np.random.seed(run_num_2)\r\n",
        "surrogate_winner_2 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_2 = GPGO_min(surrogate_winner_2, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_2.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.4359949]. \t  11013.0 \t 13577.0\n",
            "init   \t [0.27990374]. \t  12840.0 \t 13577.0\n",
            "init   \t [0.74772621]. \t  10110.0 \t 13577.0\n",
            "init   \t [0.007856]. \t  13577.0 \t 13577.0\n",
            "1      \t [0.64511479]. \t  \u001b[92m7277.0\u001b[0m \t 7277.0\n",
            "2      \t [0.93600076]. \t  \u001b[92m13728.0\u001b[0m \t 7277.0\n",
            "3      \t [0.96051377]. \t  \u001b[92m13962.0\u001b[0m \t 7277.0\n",
            "4      \t [0.88857941]. \t  \u001b[92m13154.0\u001b[0m \t 7277.0\n",
            "5      \t [0.75514332]. \t  \u001b[92m10387.0\u001b[0m \t 7277.0\n",
            "6      \t [0.98028867]. \t  \u001b[92m14019.0\u001b[0m \t 7277.0\n",
            "7      \t [0.51198591]. \t  \u001b[92m9464.0\u001b[0m \t 7277.0\n",
            "8      \t [0.0813946]. \t  \u001b[92m13505.0\u001b[0m \t 7277.0\n",
            "9      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 7277.0\n",
            "10     \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7277.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mzHrT7j14Yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f57c7a66-5751-45db-b696-034c6975f635"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 3 \r\n",
        "\r\n",
        "np.random.seed(run_num_3)\r\n",
        "surrogate_winner_3 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_3 = GPGO_min(surrogate_winner_3, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_3.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.75157561]. \t  10387.0 \t 14019.0\n",
            "init   \t [0.98028867]. \t  14019.0 \t 14019.0\n",
            "init   \t [0.51198591]. \t  9464.0 \t 14019.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 14019.0\n",
            "1      \t [0.55679391]. \t  \u001b[92m8554.0\u001b[0m \t 8554.0\n",
            "2      \t [0.44732037]. \t  \u001b[92m10874.0\u001b[0m \t 8554.0\n",
            "3      \t [0.19297376]. \t  \u001b[92m13101.0\u001b[0m \t 8554.0\n",
            "4      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 8554.0\n",
            "5      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 8554.0\n",
            "6      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 8554.0\n",
            "7      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 8554.0\n",
            "8      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 8554.0\n",
            "9      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 8554.0\n",
            "10     \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 8554.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWCaOA0q14cC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7740b0b-c56c-40dc-e9d5-733e6e81467a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 4 \r\n",
        "\r\n",
        "np.random.seed(run_num_4)\r\n",
        "surrogate_winner_4 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_4 = GPGO_min(surrogate_winner_4, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_4.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.96702984]. \t  13962.0 \t 14019.0\n",
            "init   \t [0.88857941]. \t  13154.0 \t 14019.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 14019.0\n",
            "init   \t [0.98028867]. \t  14019.0 \t 14019.0\n",
            "1      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 10387.0\n",
            "2      \t [0.35712689]. \t  \u001b[92m12143.0\u001b[0m \t 10387.0\n",
            "3      \t [0.6041957]. \t  \u001b[92m7178.0\u001b[0m \t 7178.0\n",
            "4      \t [0.56613346]. \t  \u001b[92m7747.0\u001b[0m \t 7178.0\n",
            "5      \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 7178.0\n",
            "6      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 7178.0\n",
            "7      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 7178.0\n",
            "8      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 7178.0\n",
            "9      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 7178.0\n",
            "10     \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7178.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk_ztlly14lC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c117f782-9d06-4c92-f73b-79ecbf879892"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 5 \r\n",
        "\r\n",
        "np.random.seed(run_num_5)\r\n",
        "surrogate_winner_5 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_5 = GPGO_min(surrogate_winner_5, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_5.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.71783409]. \t  9343.0 \t 13169.0\n",
            "init   \t [0.21573829]. \t  13169.0 \t 13169.0\n",
            "init   \t [0.88513393]. \t  13154.0 \t 13169.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 13169.0\n",
            "1      \t [0.49991143]. \t  \u001b[92m9953.0\u001b[0m \t 9343.0\n",
            "2      \t [0.62864525]. \t  \u001b[92m6672.0\u001b[0m \t 6672.0\n",
            "3      \t [0.09102036]. \t  \u001b[92m13585.0\u001b[0m \t 6672.0\n",
            "4      \t [0.40764505]. \t  \u001b[92m11522.0\u001b[0m \t 6672.0\n",
            "5      \t [0.26268]. \t  \u001b[92m12765.0\u001b[0m \t 6672.0\n",
            "6      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6672.0\n",
            "7      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6672.0\n",
            "8      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6672.0\n",
            "9      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6672.0\n",
            "10     \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 6672.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKgBRmWy14-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa1cdd5e-5689-4e8f-8ddd-7b9747d9f8be"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 6 \r\n",
        "\r\n",
        "np.random.seed(run_num_6)\r\n",
        "surrogate_winner_6 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_6 = GPGO_min(surrogate_winner_6, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_6.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.89286015]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "init   \t [0.26221209]. \t  12765.0 \t 13914.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13914.0\n",
            "1      \t [0.50110642]. \t  \u001b[92m9472.0\u001b[0m \t 6992.0\n",
            "2      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "3      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "4      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "5      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "6      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "7      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdqhsfhQ15C_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72b4d865-4d87-4086-c174-369012877bfc"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 7 \r\n",
        "\r\n",
        "np.random.seed(run_num_7)\r\n",
        "surrogate_winner_7 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_7 = GPGO_min(surrogate_winner_7, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_7.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.07630829]. \t  13442.0 \t 13503.0\n",
            "init   \t [0.3076631]. \t  12533.0 \t 13503.0\n",
            "init   \t [0.06469076]. \t  13503.0 \t 13503.0\n",
            "init   \t [0.51622115]. \t  9464.0 \t 13503.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 9464.0\n",
            "2      \t [0.69643796]. \t  \u001b[92m8731.0\u001b[0m \t 8731.0\n",
            "3      \t [0.66735449]. \t  \u001b[92m7888.0\u001b[0m \t 7888.0\n",
            "4      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7888.0\n",
            "5      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7888.0\n",
            "6      \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7888.0\n",
            "7      \t [0.26221209]. \t  \u001b[92m12765.0\u001b[0m \t 7888.0\n",
            "8      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "9      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "10     \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mS2c3bY15HS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5974dd71-4a39-48f7-faa0-6316d080bb77"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 8 \r\n",
        "\r\n",
        "np.random.seed(run_num_8)\r\n",
        "surrogate_winner_8 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_8 = GPGO_min(surrogate_winner_8, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_8.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.64755105]. \t  7277.0 \t 13962.0\n",
            "init   \t [0.93600076]. \t  13728.0 \t 13962.0\n",
            "init   \t [0.96051377]. \t  13962.0 \t 13962.0\n",
            "init   \t [0.88857941]. \t  13154.0 \t 13962.0\n",
            "1      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 7277.0\n",
            "2      \t [0.35392432]. \t  \u001b[92m12143.0\u001b[0m \t 7277.0\n",
            "3      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7277.0\n",
            "4      \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 7277.0\n",
            "5      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 7277.0\n",
            "6      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 7277.0\n",
            "7      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 7277.0\n",
            "8      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 7277.0\n",
            "9      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7277.0\n",
            "10     \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7277.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWr4DqE615LK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e98d18-b8f9-4577-b631-d9e77dcfe492"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 9 \r\n",
        "\r\n",
        "np.random.seed(run_num_9)\r\n",
        "surrogate_winner_9 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_9 = GPGO_min(surrogate_winner_9, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_9.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.20706637]. \t  13263.0 \t 13685.0\n",
            "init   \t [0.72910832]. \t  9585.0 \t 13685.0\n",
            "init   \t [0.80093216]. \t  11701.0 \t 13685.0\n",
            "init   \t [0.04439363]. \t  13685.0 \t 13685.0\n",
            "1      \t [0.59602262]. \t  \u001b[92m7210.0\u001b[0m \t 7210.0\n",
            "2      \t [0.47931887]. \t  \u001b[92m10418.0\u001b[0m \t 7210.0\n",
            "3      \t [0.90715029]. \t  \u001b[92m13431.0\u001b[0m \t 7210.0\n",
            "4      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7210.0\n",
            "5      \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7210.0\n",
            "6      \t [0.26221209]. \t  \u001b[92m12765.0\u001b[0m \t 7210.0\n",
            "7      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "8      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "9      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n",
            "10     \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgON7wCa15Px",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d3f1c23-df7e-452f-fea0-036bf296d894"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 10 \r\n",
        "\r\n",
        "np.random.seed(run_num_10)\r\n",
        "surrogate_winner_10 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_10 = GPGO_min(surrogate_winner_10, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_10.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.65358959]. \t  7572.0 \t 13656.0\n",
            "init   \t [0.42232996]. \t  11151.0 \t 13656.0\n",
            "init   \t [0.05316146]. \t  13656.0 \t 13656.0\n",
            "init   \t [0.00983665]. \t  13577.0 \t 13656.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7572.0\n",
            "2      \t [0.7273743]. \t  \u001b[92m9585.0\u001b[0m \t 7572.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7572.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7572.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7572.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7572.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7572.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7572.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7572.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss_C7dO615UP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090a0673-3fb1-408f-cb89-4083a3bb3ee0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 11 \r\n",
        "\r\n",
        "np.random.seed(run_num_11)\r\n",
        "surrogate_winner_11 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_11 = GPGO_min(surrogate_winner_11, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_11.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.18026969]. \t  13281.0 \t 13281.0\n",
            "init   \t [0.61298159]. \t  7424.0 \t 13281.0\n",
            "init   \t [0.29368678]. \t  12546.0 \t 13281.0\n",
            "init   \t [0.29132308]. \t  12546.0 \t 13281.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7424.0\n",
            "2      \t [0.70556665]. \t  \u001b[92m9060.0\u001b[0m \t 7424.0\n",
            "3      \t [0.0740075]. \t  \u001b[92m13442.0\u001b[0m \t 7424.0\n",
            "4      \t [0.3076631]. \t  \u001b[92m12533.0\u001b[0m \t 7424.0\n",
            "5      \t [0.06469076]. \t  \u001b[92m13503.0\u001b[0m \t 7424.0\n",
            "6      \t [0.51622115]. \t  \u001b[92m9464.0\u001b[0m \t 7424.0\n",
            "7      \t [0.0813946]. \t  \u001b[92m13505.0\u001b[0m \t 7424.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 7424.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7424.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 7424.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVqYzvY315Y9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a0196f-71c9-434d-a77b-6406f21eff62"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 12 \r\n",
        "\r\n",
        "np.random.seed(run_num_12)\r\n",
        "surrogate_winner_12 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_12 = GPGO_min(surrogate_winner_12, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_12.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.06748528]. \t  13503.0 \t 13505.0\n",
            "init   \t [0.51622115]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 9464.0\n",
            "2      \t [0.70526527]. \t  \u001b[92m9060.0\u001b[0m \t 9060.0\n",
            "3      \t [0.65613311]. \t  \u001b[92m7572.0\u001b[0m \t 7572.0\n",
            "4      \t [0.42232996]. \t  \u001b[92m11151.0\u001b[0m \t 7572.0\n",
            "5      \t [0.05316146]. \t  \u001b[92m13656.0\u001b[0m \t 7572.0\n",
            "6      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7572.0\n",
            "7      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7572.0\n",
            "8      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 7572.0\n",
            "9      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 7572.0\n",
            "10     \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAwtYRMv15d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db19a41-1ac2-4a66-a47a-8e11f47056ab"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 13 \r\n",
        "\r\n",
        "np.random.seed(run_num_13)\r\n",
        "surrogate_winner_13 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_13 = GPGO_min(surrogate_winner_13, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_13.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.77770241]. \t  10939.0 \t 13619.0\n",
            "init   \t [0.92603084]. \t  13619.0 \t 13619.0\n",
            "init   \t [0.88451529]. \t  13154.0 \t 13619.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 13619.0\n",
            "1      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 10387.0\n",
            "2      \t [0.36128067]. \t  \u001b[92m12051.0\u001b[0m \t 10387.0\n",
            "3      \t [0.62379857]. \t  \u001b[92m6672.0\u001b[0m \t 6672.0\n",
            "4      \t [0.09102036]. \t  \u001b[92m13585.0\u001b[0m \t 6672.0\n",
            "5      \t [0.40764505]. \t  \u001b[92m11522.0\u001b[0m \t 6672.0\n",
            "6      \t [0.26268]. \t  \u001b[92m12765.0\u001b[0m \t 6672.0\n",
            "7      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6672.0\n",
            "8      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6672.0\n",
            "9      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6672.0\n",
            "10     \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6672.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz33Woa215is",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac53130-526a-464b-f0f8-e3d56df54942"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 14 \r\n",
        "\r\n",
        "np.random.seed(run_num_14)\r\n",
        "surrogate_winner_14 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_14 = GPGO_min(surrogate_winner_14, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_14.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.51394334]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72684445]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zwyuIc115oH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2b0e77-bc35-4db5-846a-962ba047006a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 15 \r\n",
        "\r\n",
        "np.random.seed(run_num_15)\r\n",
        "surrogate_winner_15 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_15 = GPGO_min(surrogate_winner_15, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_15.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.65232633]. \t  7572.0 \t 13656.0\n",
            "init   \t [0.42232996]. \t  11151.0 \t 13656.0\n",
            "init   \t [0.05316146]. \t  13656.0 \t 13656.0\n",
            "init   \t [0.00983665]. \t  13577.0 \t 13656.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7572.0\n",
            "2      \t [0.72750079]. \t  \u001b[92m9585.0\u001b[0m \t 7572.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7572.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7572.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7572.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7572.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7572.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7572.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7572.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRLyr5cS15t3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f3facb-60c9-40ed-ce20-1ddce6838e54"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 16 \r\n",
        "\r\n",
        "np.random.seed(run_num_16)\r\n",
        "surrogate_winner_16 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_16 = GPGO_min(surrogate_winner_16, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_16.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.89472424]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "init   \t [0.26221209]. \t  12765.0 \t 13914.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13914.0\n",
            "1      \t [0.50227771]. \t  \u001b[92m9472.0\u001b[0m \t 6992.0\n",
            "2      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "3      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "4      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "5      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "6      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "7      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFnuBlG515zz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea02ce63-d097-4f4c-f3a5-2c17e20ef6bb"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 17 \r\n",
        "\r\n",
        "np.random.seed(run_num_17)\r\n",
        "surrogate_winner_17 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_17 = GPGO_min(surrogate_winner_17, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_17.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.03062042]. \t  13305.0 \t 13505.0\n",
            "init   \t [0.08122315]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72740156]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWK-H-6Y157M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a3fb5f-5951-43fe-8b4c-61381645c361"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 18 \r\n",
        "\r\n",
        "np.random.seed(run_num_18)\r\n",
        "surrogate_winner_18 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_18 = GPGO_min(surrogate_winner_18, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_18.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.51197762]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72640919]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y924TuRx16Dm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9266045-e85f-4983-fb4d-8012f2d52f4a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 19 \r\n",
        "\r\n",
        "np.random.seed(run_num_19)\r\n",
        "surrogate_winner_19 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_19 = GPGO_min(surrogate_winner_19, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_19.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.0975336]. \t  13585.0 \t 13585.0\n",
            "init   \t [0.40764505]. \t  11522.0 \t 13585.0\n",
            "init   \t [0.26268]. \t  12765.0 \t 13585.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13585.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "2      \t [0.74411423]. \t  \u001b[92m10110.0\u001b[0m \t 6992.0\n",
            "3      \t [0.007856]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "4      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "5      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "6      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "7      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "8      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "9      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "10     \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONx9ETQg16KN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9419f565-76d5-4d9f-b6f6-f6a9dcabd9cf"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 20 \r\n",
        "\r\n",
        "np.random.seed(run_num_20)\r\n",
        "surrogate_winner_20 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_20 = GPGO_min(surrogate_winner_20, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_20.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.5881308]. \t  7940.0 \t 13914.0\n",
            "init   \t [0.90925644]. \t  13431.0 \t 13914.0\n",
            "init   \t [0.89555325]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "1      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 7940.0\n",
            "2      \t [0.36456158]. \t  \u001b[92m12051.0\u001b[0m \t 7940.0\n",
            "3      \t [0.1964637]. \t  \u001b[92m13101.0\u001b[0m \t 7940.0\n",
            "4      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 7940.0\n",
            "5      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 7940.0\n",
            "6      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 7940.0\n",
            "7      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 7940.0\n",
            "8      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7940.0\n",
            "9      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7940.0\n",
            "10     \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 7940.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qfV1wj83xw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb509bf-13cd-4c1b-bc23-b18164d80a17"
      },
      "source": [
        "end_win = time.time()\r\n",
        "end_win\r\n",
        "\r\n",
        "time_win = end_win - start_win\r\n",
        "time_win"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1247.4514355659485"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj_BXyha3yPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65c21834-e24c-49c2-f60f-82149204fd1b"
      },
      "source": [
        "### Training regret minimization: run number = 1\r\n",
        "\r\n",
        "loser_output_1 = np.append(np.max(loser_1.GP.y[0:n_init]),loser_1.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_1 = np.append(np.max(winner_1.GP.y[0:n_init]),winner_1.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_1 = np.log(-y_global_orig + loser_output_1)\r\n",
        "regret_winner_1 = np.log(-y_global_orig + winner_output_1)\r\n",
        "\r\n",
        "train_regret_loser_1 = min_max_array(regret_loser_1)\r\n",
        "train_regret_winner_1 = min_max_array(regret_winner_1)\r\n",
        "\r\n",
        "min_train_regret_loser_1 = min(train_regret_loser_1)\r\n",
        "min_train_regret_winner_1 = min(train_regret_winner_1)\r\n",
        "\r\n",
        "min_train_regret_loser_1, min_train_regret_winner_1"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.852521917335372, 8.852521917335372)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Jzxu4qEgxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a873117-0b3f-4113-edf6-076f26d1f981"
      },
      "source": [
        "### Training regret minimization: run number = 2\r\n",
        "\r\n",
        "loser_output_2 = np.append(np.max(loser_2.GP.y[0:n_init]),loser_2.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_2 = np.append(np.max(winner_2.GP.y[0:n_init]),winner_2.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_2 = np.log(-y_global_orig + loser_output_2)\r\n",
        "regret_winner_2 = np.log(-y_global_orig + winner_output_2)\r\n",
        "\r\n",
        "train_regret_loser_2 = min_max_array(regret_loser_2)\r\n",
        "train_regret_winner_2 = min_max_array(regret_winner_2)\r\n",
        "\r\n",
        "min_train_regret_loser_2 = min(train_regret_loser_2)\r\n",
        "min_train_regret_winner_2 = min(train_regret_winner_2)\r\n",
        "\r\n",
        "min_train_regret_loser_2, min_train_regret_winner_2"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.805674944038582, 8.892473968347087)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suF8efHHEg3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9657f516-a332-4600-e584-d2a52cf7b247"
      },
      "source": [
        "### Training regret minimization: run number = 3\r\n",
        "\r\n",
        "loser_output_3 = np.append(np.max(loser_3.GP.y[0:n_init]),loser_3.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_3 = np.append(np.max(winner_3.GP.y[0:n_init]),winner_3.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_3 = np.log(-y_global_orig + loser_output_3)\r\n",
        "regret_winner_3 = np.log(-y_global_orig + winner_output_3)\r\n",
        "\r\n",
        "train_regret_loser_3 = min_max_array(regret_loser_3)\r\n",
        "train_regret_winner_3 = min_max_array(regret_winner_3)\r\n",
        "\r\n",
        "min_train_regret_loser_3 = min(train_regret_loser_3)\r\n",
        "min_train_regret_winner_3 = min(train_regret_winner_3)\r\n",
        "\r\n",
        "min_train_regret_loser_3, min_train_regret_winner_3"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.054154288786854, 9.054154288786854)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPemfBgeEg8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c017a874-3b5d-413e-c6eb-5dd13301585c"
      },
      "source": [
        "### Training regret minimization: run number = 4\r\n",
        "\r\n",
        "loser_output_4 = np.append(np.max(loser_4.GP.y[0:n_init]),loser_4.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_4 = np.append(np.max(winner_4.GP.y[0:n_init]),winner_4.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_4 = np.log(-y_global_orig + loser_output_4)\r\n",
        "regret_winner_4 = np.log(-y_global_orig + winner_output_4)\r\n",
        "\r\n",
        "train_regret_loser_4 = min_max_array(regret_loser_4)\r\n",
        "train_regret_winner_4 = min_max_array(regret_winner_4)\r\n",
        "\r\n",
        "min_train_regret_loser_4 = min(train_regret_loser_4)\r\n",
        "min_train_regret_winner_4 = min(train_regret_winner_4)\r\n",
        "\r\n",
        "min_train_regret_loser_4, min_train_regret_winner_4"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.852521917335372, 8.878776071707552)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5SRriB83yR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0f0751a-512c-4aac-d005-671a816e7ab7"
      },
      "source": [
        "### Training regret minimization: run number = 5\r\n",
        "\r\n",
        "loser_output_5 = np.append(np.max(loser_5.GP.y[0:n_init]),loser_5.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_5 = np.append(np.max(winner_5.GP.y[0:n_init]),winner_5.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_5 = np.log(-y_global_orig + loser_output_5)\r\n",
        "regret_winner_5 = np.log(-y_global_orig + winner_output_5)\r\n",
        "\r\n",
        "train_regret_loser_5 = min_max_array(regret_loser_5)\r\n",
        "train_regret_winner_5 = min_max_array(regret_winner_5)\r\n",
        "\r\n",
        "min_train_regret_loser_5 = min(train_regret_loser_5)\r\n",
        "min_train_regret_winner_5 = min(train_regret_winner_5)\r\n",
        "\r\n",
        "min_train_regret_loser_5, min_train_regret_winner_5"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.878776071707552, 8.805674944038582)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUVta_GJFFaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7dcbc05-fffb-49a7-e2e3-a55f97cdca7c"
      },
      "source": [
        "### Training regret minimization: run number = 6\r\n",
        "\r\n",
        "loser_output_6 = np.append(np.max(loser_6.GP.y[0:n_init]),loser_6.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_6 = np.append(np.max(winner_6.GP.y[0:n_init]),winner_6.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_6 = np.log(-y_global_orig + loser_output_6)\r\n",
        "regret_winner_6 = np.log(-y_global_orig + winner_output_6)\r\n",
        "\r\n",
        "train_regret_loser_6 = min_max_array(regret_loser_6)\r\n",
        "train_regret_winner_6 = min_max_array(regret_winner_6)\r\n",
        "\r\n",
        "min_train_regret_loser_6 = min(train_regret_loser_6)\r\n",
        "min_train_regret_winner_6 = min(train_regret_winner_6)\r\n",
        "\r\n",
        "min_train_regret_loser_6, min_train_regret_winner_6"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.955060950631902)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7V7-xKKFFm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eebe964-635a-47d0-b7bd-3d5b17d77547"
      },
      "source": [
        "### Training regret minimization: run number = 7\r\n",
        "\r\n",
        "loser_output_7 = np.append(np.max(loser_7.GP.y[0:n_init]),loser_7.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_7 = np.append(np.max(winner_7.GP.y[0:n_init]),winner_7.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_7 = np.log(-y_global_orig + loser_output_7)\r\n",
        "regret_winner_7 = np.log(-y_global_orig + winner_output_7)\r\n",
        "\r\n",
        "train_regret_loser_7 = min_max_array(regret_loser_7)\r\n",
        "train_regret_winner_7 = min_max_array(regret_winner_7)\r\n",
        "\r\n",
        "min_train_regret_loser_7 = min(train_regret_loser_7)\r\n",
        "min_train_regret_winner_7 = min(train_regret_winner_7)\r\n",
        "\r\n",
        "min_train_regret_loser_7, min_train_regret_winner_7"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.00859131751613, 8.852521917335372)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMQ0rwZoFFuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e704022-5c51-4a89-e0af-39f6c0a4de3b"
      },
      "source": [
        "### Training regret minimization: run number = 8\r\n",
        "\r\n",
        "loser_output_8 = np.append(np.max(loser_8.GP.y[0:n_init]),loser_8.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_8 = np.append(np.max(winner_8.GP.y[0:n_init]),winner_8.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_8 = np.log(-y_global_orig + loser_output_8)\r\n",
        "regret_winner_8 = np.log(-y_global_orig + winner_output_8)\r\n",
        "\r\n",
        "train_regret_loser_8 = min_max_array(regret_loser_8)\r\n",
        "train_regret_winner_8 = min_max_array(regret_winner_8)\r\n",
        "\r\n",
        "min_train_regret_loser_8 = min(train_regret_loser_8)\r\n",
        "min_train_regret_winner_8 = min(train_regret_winner_8)\r\n",
        "\r\n",
        "min_train_regret_loser_8, min_train_regret_winner_8"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.852521917335372, 8.955060950631902)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW39Qs4ZFFzr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a26a140-5ef4-4afa-84a9-28dbf046a1d0"
      },
      "source": [
        "### Training regret minimization: run number = 9\r\n",
        "\r\n",
        "loser_output_9 = np.append(np.max(loser_9.GP.y[0:n_init]),loser_9.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_9 = np.append(np.max(winner_9.GP.y[0:n_init]),winner_9.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_9 = np.log(-y_global_orig + loser_output_9)\r\n",
        "regret_winner_9 = np.log(-y_global_orig + winner_output_9)\r\n",
        "\r\n",
        "train_regret_loser_9 = min_max_array(regret_loser_9)\r\n",
        "train_regret_winner_9 = min_max_array(regret_winner_9)\r\n",
        "\r\n",
        "min_train_regret_loser_9 = min(train_regret_loser_9)\r\n",
        "min_train_regret_winner_9 = min(train_regret_winner_9)\r\n",
        "\r\n",
        "min_train_regret_loser_9, min_train_regret_winner_9"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.852521917335372, 8.852521917335372)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH5fvkDWFF4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd36d4f-5d80-41e8-c8a7-79118ca64610"
      },
      "source": [
        "### Training regret minimization: run number = 10\r\n",
        "\r\n",
        "loser_output_10 = np.append(np.max(loser_10.GP.y[0:n_init]),loser_10.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_10 = np.append(np.max(winner_10.GP.y[0:n_init]),winner_10.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_10 = np.log(-y_global_orig + loser_output_10)\r\n",
        "regret_winner_10 = np.log(-y_global_orig + winner_output_10)\r\n",
        "\r\n",
        "train_regret_loser_10 = min_max_array(regret_loser_10)\r\n",
        "train_regret_winner_10 = min_max_array(regret_winner_10)\r\n",
        "\r\n",
        "min_train_regret_loser_10 = min(train_regret_loser_10)\r\n",
        "min_train_regret_winner_10 = min(train_regret_winner_10)\r\n",
        "\r\n",
        "min_train_regret_loser_10, min_train_regret_winner_10"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.973097896282471)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdGgTNueFF8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cff80b28-2957-4201-86ba-877703d420c2"
      },
      "source": [
        "### Training regret minimization: run number = 11\r\n",
        "\r\n",
        "loser_output_11 = np.append(np.max(loser_11.GP.y[0:n_init]),loser_11.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_11 = np.append(np.max(winner_11.GP.y[0:n_init]),winner_11.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_11 = np.log(-y_global_orig + loser_output_11)\r\n",
        "regret_winner_11 = np.log(-y_global_orig + winner_output_11)\r\n",
        "\r\n",
        "train_regret_loser_11 = min_max_array(regret_loser_11)\r\n",
        "train_regret_winner_11 = min_max_array(regret_winner_11)\r\n",
        "\r\n",
        "min_train_regret_loser_11 = min(train_regret_loser_11)\r\n",
        "min_train_regret_winner_11 = min(train_regret_winner_11)\r\n",
        "\r\n",
        "min_train_regret_loser_11, min_train_regret_winner_11"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.955060950631902)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVeNgJSbFGAM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aea68ba-73d4-420f-b5af-49e2259130d1"
      },
      "source": [
        "### Training regret minimization: run number = 12\r\n",
        "\r\n",
        "loser_output_12 = np.append(np.max(loser_12.GP.y[0:n_init]),loser_12.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_12 = np.append(np.max(winner_12.GP.y[0:n_init]),winner_12.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_12 = np.log(-y_global_orig + loser_output_12)\r\n",
        "regret_winner_12 = np.log(-y_global_orig + winner_output_12)\r\n",
        "\r\n",
        "train_regret_loser_12 = min_max_array(regret_loser_12)\r\n",
        "train_regret_winner_12 = min_max_array(regret_winner_12)\r\n",
        "\r\n",
        "min_train_regret_loser_12 = min(train_regret_loser_12)\r\n",
        "min_train_regret_winner_12 = min(train_regret_winner_12)\r\n",
        "\r\n",
        "min_train_regret_loser_12, min_train_regret_winner_12"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.932212512329214, 8.932212512329214)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GIrEFAMFGD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a8c2b66-448f-4f3a-dd9e-2186ca22d404"
      },
      "source": [
        "### Training regret minimization: run number = 13\r\n",
        "\r\n",
        "loser_output_13 = np.append(np.max(loser_13.GP.y[0:n_init]),loser_13.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_13 = np.append(np.max(winner_13.GP.y[0:n_init]),winner_13.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_13 = np.log(-y_global_orig + loser_output_13)\r\n",
        "regret_winner_13 = np.log(-y_global_orig + winner_output_13)\r\n",
        "\r\n",
        "train_regret_loser_13 = min_max_array(regret_loser_13)\r\n",
        "train_regret_winner_13 = min_max_array(regret_winner_13)\r\n",
        "\r\n",
        "min_train_regret_loser_13 = min(train_regret_loser_13)\r\n",
        "min_train_regret_winner_13 = min(train_regret_winner_13)\r\n",
        "\r\n",
        "min_train_regret_loser_13, min_train_regret_winner_13"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.805674944038582, 8.805674944038582)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV0iCAUQFGIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95034cda-58c9-43e9-fb30-992cfdf4b932"
      },
      "source": [
        "### Training regret minimization: run number = 14\r\n",
        "\r\n",
        "loser_output_14 = np.append(np.max(loser_14.GP.y[0:n_init]),loser_14.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_14 = np.append(np.max(winner_14.GP.y[0:n_init]),winner_14.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_14 = np.log(-y_global_orig + loser_output_14)\r\n",
        "regret_winner_14 = np.log(-y_global_orig + winner_output_14)\r\n",
        "\r\n",
        "train_regret_loser_14 = min_max_array(regret_loser_14)\r\n",
        "train_regret_winner_14 = min_max_array(regret_winner_14)\r\n",
        "\r\n",
        "min_train_regret_loser_14 = min(train_regret_loser_14)\r\n",
        "min_train_regret_winner_14 = min(train_regret_winner_14)\r\n",
        "\r\n",
        "min_train_regret_loser_14, min_train_regret_winner_14"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.973097896282471, 8.973097896282471)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJqZhhnBFGMm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bed6ef5-2530-4afd-e6ce-1cea0b18aafa"
      },
      "source": [
        "### Training regret minimization: run number = 15\r\n",
        "\r\n",
        "loser_output_15 = np.append(np.max(loser_15.GP.y[0:n_init]),loser_15.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_15 = np.append(np.max(winner_15.GP.y[0:n_init]),winner_15.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_15 = np.log(-y_global_orig + loser_output_15)\r\n",
        "regret_winner_15 = np.log(-y_global_orig + winner_output_15)\r\n",
        "\r\n",
        "train_regret_loser_15 = min_max_array(regret_loser_15)\r\n",
        "train_regret_winner_15 = min_max_array(regret_winner_15)\r\n",
        "\r\n",
        "min_train_regret_loser_15 = min(train_regret_loser_15)\r\n",
        "min_train_regret_winner_15 = min(train_regret_winner_15)\r\n",
        "\r\n",
        "min_train_regret_loser_15, min_train_regret_winner_15"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.973097896282471)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPmJ7j3RFGRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b9792ff-ec54-414a-f467-015413b3ad84"
      },
      "source": [
        "### Training regret minimization: run number = 16\r\n",
        "\r\n",
        "loser_output_16 = np.append(np.max(loser_16.GP.y[0:n_init]),loser_16.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_16 = np.append(np.max(winner_16.GP.y[0:n_init]),winner_16.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_16 = np.log(-y_global_orig + loser_output_16)\r\n",
        "regret_winner_16 = np.log(-y_global_orig + winner_output_16)\r\n",
        "\r\n",
        "train_regret_loser_16 = min_max_array(regret_loser_16)\r\n",
        "train_regret_winner_16 = min_max_array(regret_winner_16)\r\n",
        "\r\n",
        "min_train_regret_loser_16 = min(train_regret_loser_16)\r\n",
        "min_train_regret_winner_16 = min(train_regret_winner_16)\r\n",
        "\r\n",
        "min_train_regret_loser_16, min_train_regret_winner_16"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.955060950631902)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfyyMg-bFGWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fa9ee21-09dc-4fc9-aad0-3b62470e9fe6"
      },
      "source": [
        "### Training regret minimization: run number = 17\r\n",
        "\r\n",
        "loser_output_17 = np.append(np.max(loser_17.GP.y[0:n_init]),loser_17.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_17 = np.append(np.max(winner_17.GP.y[0:n_init]),winner_17.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_17 = np.log(-y_global_orig + loser_output_17)\r\n",
        "regret_winner_17 = np.log(-y_global_orig + winner_output_17)\r\n",
        "\r\n",
        "train_regret_loser_17 = min_max_array(regret_loser_17)\r\n",
        "train_regret_winner_17 = min_max_array(regret_winner_17)\r\n",
        "\r\n",
        "min_train_regret_loser_17 = min(train_regret_loser_17)\r\n",
        "min_train_regret_winner_17 = min(train_regret_winner_17)\r\n",
        "\r\n",
        "min_train_regret_loser_17, min_train_regret_winner_17"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.973097896282471, 8.973097896282471)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WS6hJYuFGa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b85ff192-f163-42fa-879b-a1c39d9b739c"
      },
      "source": [
        "### Training regret minimization: run number = 18\r\n",
        "\r\n",
        "loser_output_18 = np.append(np.max(loser_18.GP.y[0:n_init]),loser_18.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_18 = np.append(np.max(winner_18.GP.y[0:n_init]),winner_18.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_18 = np.log(-y_global_orig + loser_output_18)\r\n",
        "regret_winner_18 = np.log(-y_global_orig + winner_output_18)\r\n",
        "\r\n",
        "train_regret_loser_18 = min_max_array(regret_loser_18)\r\n",
        "train_regret_winner_18 = min_max_array(regret_winner_18)\r\n",
        "\r\n",
        "min_train_regret_loser_18 = min(train_regret_loser_18)\r\n",
        "min_train_regret_winner_18 = min(train_regret_winner_18)\r\n",
        "\r\n",
        "min_train_regret_loser_18, min_train_regret_winner_18"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.973097896282471, 8.973097896282471)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErcIOoOXFGgS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbdce9e9-8926-4548-b881-ec27f5ea3d52"
      },
      "source": [
        "### Training regret minimization: run number = 19\r\n",
        "\r\n",
        "loser_output_19 = np.append(np.max(loser_19.GP.y[0:n_init]),loser_19.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_19 = np.append(np.max(winner_19.GP.y[0:n_init]),winner_19.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_19 = np.log(-y_global_orig + loser_output_19)\r\n",
        "regret_winner_19 = np.log(-y_global_orig + winner_output_19)\r\n",
        "\r\n",
        "train_regret_loser_19 = min_max_array(regret_loser_19)\r\n",
        "train_regret_winner_19 = min_max_array(regret_winner_19)\r\n",
        "\r\n",
        "min_train_regret_loser_19 = min(train_regret_loser_19)\r\n",
        "min_train_regret_winner_19 = min(train_regret_winner_19)\r\n",
        "\r\n",
        "min_train_regret_loser_19, min_train_regret_winner_19"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.955060950631902)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbOsumB6FGlD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a6a6a9d-da21-4709-c508-e67394b73ddb"
      },
      "source": [
        "### Training regret minimization: run number = 20\r\n",
        "\r\n",
        "loser_output_20 = np.append(np.max(loser_20.GP.y[0:n_init]),loser_20.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_20 = np.append(np.max(winner_20.GP.y[0:n_init]),winner_20.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_20 = np.log(-y_global_orig + loser_output_20)\r\n",
        "regret_winner_20 = np.log(-y_global_orig + winner_output_20)\r\n",
        "\r\n",
        "train_regret_loser_20 = min_max_array(regret_loser_20)\r\n",
        "train_regret_winner_20 = min_max_array(regret_winner_20)\r\n",
        "\r\n",
        "min_train_regret_loser_20 = min(train_regret_loser_20)\r\n",
        "min_train_regret_winner_20 = min(train_regret_winner_20)\r\n",
        "\r\n",
        "min_train_regret_loser_20, min_train_regret_winner_20"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.32259705432185, 9.32259705432185)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89S668T8GSeJ"
      },
      "source": [
        "# Iteration1 :\r\n",
        "\r\n",
        "slice1 = 0\r\n",
        "\r\n",
        "loser1 = [train_regret_loser_1[slice1],\r\n",
        "       train_regret_loser_2[slice1],\r\n",
        "       train_regret_loser_3[slice1],\r\n",
        "       train_regret_loser_4[slice1],\r\n",
        "       train_regret_loser_5[slice1],\r\n",
        "       train_regret_loser_6[slice1],\r\n",
        "       train_regret_loser_7[slice1],\r\n",
        "       train_regret_loser_8[slice1],\r\n",
        "       train_regret_loser_9[slice1],\r\n",
        "       train_regret_loser_10[slice1],\r\n",
        "       train_regret_loser_11[slice1],\r\n",
        "       train_regret_loser_12[slice1],\r\n",
        "       train_regret_loser_13[slice1],\r\n",
        "       train_regret_loser_14[slice1],\r\n",
        "       train_regret_loser_15[slice1],\r\n",
        "       train_regret_loser_16[slice1],\r\n",
        "       train_regret_loser_17[slice1],\r\n",
        "       train_regret_loser_18[slice1],\r\n",
        "       train_regret_loser_19[slice1],\r\n",
        "       train_regret_loser_20[slice1]]\r\n",
        "\r\n",
        "winner1 = [train_regret_winner_1[slice1],\r\n",
        "       train_regret_winner_2[slice1],\r\n",
        "       train_regret_winner_3[slice1],\r\n",
        "       train_regret_winner_4[slice1],\r\n",
        "       train_regret_winner_5[slice1],\r\n",
        "       train_regret_winner_6[slice1],\r\n",
        "       train_regret_winner_7[slice1],\r\n",
        "       train_regret_winner_8[slice1],\r\n",
        "       train_regret_winner_9[slice1],\r\n",
        "       train_regret_winner_10[slice1],\r\n",
        "       train_regret_winner_11[slice1],\r\n",
        "       train_regret_winner_12[slice1],\r\n",
        "       train_regret_winner_13[slice1],\r\n",
        "       train_regret_winner_14[slice1],\r\n",
        "       train_regret_winner_15[slice1],\r\n",
        "       train_regret_winner_16[slice1],\r\n",
        "       train_regret_winner_17[slice1],\r\n",
        "       train_regret_winner_18[slice1],\r\n",
        "       train_regret_winner_19[slice1],\r\n",
        "       train_regret_winner_20[slice1]]\r\n",
        "\r\n",
        "loser1_results = pd.DataFrame(loser1).sort_values(by=[0], ascending=False)\r\n",
        "winner1_results = pd.DataFrame(winner1).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser1 = np.asarray(loser1_results[4:5][0])[0]\r\n",
        "median_loser1 = np.asarray(loser1_results[9:10][0])[0]\r\n",
        "upper_loser1 = np.asarray(loser1_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner1 = np.asarray(winner1_results[4:5][0])[0]\r\n",
        "median_winner1 = np.asarray(winner1_results[9:10][0])[0]\r\n",
        "upper_winner1 = np.asarray(winner1_results[14:15][0])[0]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CbMKkbYGSmk"
      },
      "source": [
        "# Iteration11 :\r\n",
        "\r\n",
        "slice11 = 10\r\n",
        "\r\n",
        "loser11 = [train_regret_loser_1[slice11],\r\n",
        "       train_regret_loser_2[slice11],\r\n",
        "       train_regret_loser_3[slice11],\r\n",
        "       train_regret_loser_4[slice11],\r\n",
        "       train_regret_loser_5[slice11],\r\n",
        "       train_regret_loser_6[slice11],\r\n",
        "       train_regret_loser_7[slice11],\r\n",
        "       train_regret_loser_8[slice11],\r\n",
        "       train_regret_loser_9[slice11],\r\n",
        "       train_regret_loser_10[slice11],\r\n",
        "       train_regret_loser_11[slice11],\r\n",
        "       train_regret_loser_12[slice11],\r\n",
        "       train_regret_loser_13[slice11],\r\n",
        "       train_regret_loser_14[slice11],\r\n",
        "       train_regret_loser_15[slice11],\r\n",
        "       train_regret_loser_16[slice11],\r\n",
        "       train_regret_loser_17[slice11],\r\n",
        "       train_regret_loser_18[slice11],\r\n",
        "       train_regret_loser_19[slice11],\r\n",
        "       train_regret_loser_20[slice11]]\r\n",
        "\r\n",
        "winner11 = [train_regret_winner_1[slice11],\r\n",
        "       train_regret_winner_2[slice11],\r\n",
        "       train_regret_winner_3[slice11],\r\n",
        "       train_regret_winner_4[slice11],\r\n",
        "       train_regret_winner_5[slice11],\r\n",
        "       train_regret_winner_6[slice11],\r\n",
        "       train_regret_winner_7[slice11],\r\n",
        "       train_regret_winner_8[slice11],\r\n",
        "       train_regret_winner_9[slice11],\r\n",
        "       train_regret_winner_10[slice11],\r\n",
        "       train_regret_winner_11[slice11],\r\n",
        "       train_regret_winner_12[slice11],\r\n",
        "       train_regret_winner_13[slice11],\r\n",
        "       train_regret_winner_14[slice11],\r\n",
        "       train_regret_winner_15[slice11],\r\n",
        "       train_regret_winner_16[slice11],\r\n",
        "       train_regret_winner_17[slice11],\r\n",
        "       train_regret_winner_18[slice11],\r\n",
        "       train_regret_winner_19[slice11],\r\n",
        "       train_regret_winner_20[slice11]]\r\n",
        "\r\n",
        "loser11_results = pd.DataFrame(loser11).sort_values(by=[0], ascending=False)\r\n",
        "winner11_results = pd.DataFrame(winner11).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser11 = np.asarray(loser11_results[4:5][0])[0]\r\n",
        "median_loser11 = np.asarray(loser11_results[9:10][0])[0]\r\n",
        "upper_loser11 = np.asarray(loser11_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner11 = np.asarray(winner11_results[4:5][0])[0]\r\n",
        "median_winner11 = np.asarray(winner11_results[9:10][0])[0]\r\n",
        "upper_winner11 = np.asarray(winner11_results[14:15][0])[0]"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dqqsAbZGSto"
      },
      "source": [
        "# Iteration2 :\r\n",
        "\r\n",
        "slice2 = 1\r\n",
        "\r\n",
        "loser2 = [train_regret_loser_1[slice2],\r\n",
        "       train_regret_loser_2[slice2],\r\n",
        "       train_regret_loser_3[slice2],\r\n",
        "       train_regret_loser_4[slice2],\r\n",
        "       train_regret_loser_5[slice2],\r\n",
        "       train_regret_loser_6[slice2],\r\n",
        "       train_regret_loser_7[slice2],\r\n",
        "       train_regret_loser_8[slice2],\r\n",
        "       train_regret_loser_9[slice2],\r\n",
        "       train_regret_loser_10[slice2],\r\n",
        "       train_regret_loser_11[slice2],\r\n",
        "       train_regret_loser_12[slice2],\r\n",
        "       train_regret_loser_13[slice2],\r\n",
        "       train_regret_loser_14[slice2],\r\n",
        "       train_regret_loser_15[slice2],\r\n",
        "       train_regret_loser_16[slice2],\r\n",
        "       train_regret_loser_17[slice2],\r\n",
        "       train_regret_loser_18[slice2],\r\n",
        "       train_regret_loser_19[slice2],\r\n",
        "       train_regret_loser_20[slice2]]\r\n",
        "\r\n",
        "winner2 = [train_regret_winner_1[slice2],\r\n",
        "       train_regret_winner_2[slice2],\r\n",
        "       train_regret_winner_3[slice2],\r\n",
        "       train_regret_winner_4[slice2],\r\n",
        "       train_regret_winner_5[slice2],\r\n",
        "       train_regret_winner_6[slice2],\r\n",
        "       train_regret_winner_7[slice2],\r\n",
        "       train_regret_winner_8[slice2],\r\n",
        "       train_regret_winner_9[slice2],\r\n",
        "       train_regret_winner_10[slice2],\r\n",
        "       train_regret_winner_11[slice2],\r\n",
        "       train_regret_winner_12[slice2],\r\n",
        "       train_regret_winner_13[slice2],\r\n",
        "       train_regret_winner_14[slice2],\r\n",
        "       train_regret_winner_15[slice2],\r\n",
        "       train_regret_winner_16[slice2],\r\n",
        "       train_regret_winner_17[slice2],\r\n",
        "       train_regret_winner_18[slice2],\r\n",
        "       train_regret_winner_19[slice2],\r\n",
        "       train_regret_winner_20[slice2]]\r\n",
        "\r\n",
        "loser2_results = pd.DataFrame(loser2).sort_values(by=[0], ascending=False)\r\n",
        "winner2_results = pd.DataFrame(winner2).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser2 = np.asarray(loser2_results[4:5][0])[0]\r\n",
        "median_loser2 = np.asarray(loser2_results[9:10][0])[0]\r\n",
        "upper_loser2 = np.asarray(loser2_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner2 = np.asarray(winner2_results[4:5][0])[0]\r\n",
        "median_winner2 = np.asarray(winner2_results[9:10][0])[0]\r\n",
        "upper_winner2 = np.asarray(winner2_results[14:15][0])[0]"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT1vdmweGSza"
      },
      "source": [
        "# Iteration3 :\r\n",
        "\r\n",
        "slice3 = 2\r\n",
        "\r\n",
        "loser3 = [train_regret_loser_1[slice3],\r\n",
        "       train_regret_loser_2[slice3],\r\n",
        "       train_regret_loser_3[slice3],\r\n",
        "       train_regret_loser_4[slice3],\r\n",
        "       train_regret_loser_5[slice3],\r\n",
        "       train_regret_loser_6[slice3],\r\n",
        "       train_regret_loser_7[slice3],\r\n",
        "       train_regret_loser_8[slice3],\r\n",
        "       train_regret_loser_9[slice3],\r\n",
        "       train_regret_loser_10[slice3],\r\n",
        "       train_regret_loser_11[slice3],\r\n",
        "       train_regret_loser_12[slice3],\r\n",
        "       train_regret_loser_13[slice3],\r\n",
        "       train_regret_loser_14[slice3],\r\n",
        "       train_regret_loser_15[slice3],\r\n",
        "       train_regret_loser_16[slice3],\r\n",
        "       train_regret_loser_17[slice3],\r\n",
        "       train_regret_loser_18[slice3],\r\n",
        "       train_regret_loser_19[slice3],\r\n",
        "       train_regret_loser_20[slice3]]\r\n",
        "\r\n",
        "winner3 = [train_regret_winner_1[slice3],\r\n",
        "       train_regret_winner_2[slice3],\r\n",
        "       train_regret_winner_3[slice3],\r\n",
        "       train_regret_winner_4[slice3],\r\n",
        "       train_regret_winner_5[slice3],\r\n",
        "       train_regret_winner_6[slice3],\r\n",
        "       train_regret_winner_7[slice3],\r\n",
        "       train_regret_winner_8[slice3],\r\n",
        "       train_regret_winner_9[slice3],\r\n",
        "       train_regret_winner_10[slice3],\r\n",
        "       train_regret_winner_11[slice3],\r\n",
        "       train_regret_winner_12[slice3],\r\n",
        "       train_regret_winner_13[slice3],\r\n",
        "       train_regret_winner_14[slice3],\r\n",
        "       train_regret_winner_15[slice3],\r\n",
        "       train_regret_winner_16[slice3],\r\n",
        "       train_regret_winner_17[slice3],\r\n",
        "       train_regret_winner_18[slice3],\r\n",
        "       train_regret_winner_19[slice3],\r\n",
        "       train_regret_winner_20[slice3]]\r\n",
        "\r\n",
        "loser3_results = pd.DataFrame(loser3).sort_values(by=[0], ascending=False)\r\n",
        "winner3_results = pd.DataFrame(winner3).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser3 = np.asarray(loser3_results[4:5][0])[0]\r\n",
        "median_loser3 = np.asarray(loser3_results[9:10][0])[0]\r\n",
        "upper_loser3 = np.asarray(loser3_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner3 = np.asarray(winner3_results[4:5][0])[0]\r\n",
        "median_winner3 = np.asarray(winner3_results[9:10][0])[0]\r\n",
        "upper_winner3 = np.asarray(winner3_results[14:15][0])[0]"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXZrawn0GS4Z"
      },
      "source": [
        "# Iteration4 :\r\n",
        "\r\n",
        "slice4 = 3\r\n",
        "\r\n",
        "loser4 = [train_regret_loser_1[slice4],\r\n",
        "       train_regret_loser_2[slice4],\r\n",
        "       train_regret_loser_3[slice4],\r\n",
        "       train_regret_loser_4[slice4],\r\n",
        "       train_regret_loser_5[slice4],\r\n",
        "       train_regret_loser_6[slice4],\r\n",
        "       train_regret_loser_7[slice4],\r\n",
        "       train_regret_loser_8[slice4],\r\n",
        "       train_regret_loser_9[slice4],\r\n",
        "       train_regret_loser_10[slice4],\r\n",
        "       train_regret_loser_11[slice4],\r\n",
        "       train_regret_loser_12[slice4],\r\n",
        "       train_regret_loser_13[slice4],\r\n",
        "       train_regret_loser_14[slice4],\r\n",
        "       train_regret_loser_15[slice4],\r\n",
        "       train_regret_loser_16[slice4],\r\n",
        "       train_regret_loser_17[slice4],\r\n",
        "       train_regret_loser_18[slice4],\r\n",
        "       train_regret_loser_19[slice4],\r\n",
        "       train_regret_loser_20[slice4]]\r\n",
        "\r\n",
        "winner4 = [train_regret_winner_1[slice4],\r\n",
        "       train_regret_winner_2[slice4],\r\n",
        "       train_regret_winner_3[slice4],\r\n",
        "       train_regret_winner_4[slice4],\r\n",
        "       train_regret_winner_5[slice4],\r\n",
        "       train_regret_winner_6[slice4],\r\n",
        "       train_regret_winner_7[slice4],\r\n",
        "       train_regret_winner_8[slice4],\r\n",
        "       train_regret_winner_9[slice4],\r\n",
        "       train_regret_winner_10[slice4],\r\n",
        "       train_regret_winner_11[slice4],\r\n",
        "       train_regret_winner_12[slice4],\r\n",
        "       train_regret_winner_13[slice4],\r\n",
        "       train_regret_winner_14[slice4],\r\n",
        "       train_regret_winner_15[slice4],\r\n",
        "       train_regret_winner_16[slice4],\r\n",
        "       train_regret_winner_17[slice4],\r\n",
        "       train_regret_winner_18[slice4],\r\n",
        "       train_regret_winner_19[slice4],\r\n",
        "       train_regret_winner_20[slice4]]\r\n",
        "\r\n",
        "loser4_results = pd.DataFrame(loser4).sort_values(by=[0], ascending=False)\r\n",
        "winner4_results = pd.DataFrame(winner4).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser4 = np.asarray(loser4_results[4:5][0])[0]\r\n",
        "median_loser4 = np.asarray(loser4_results[9:10][0])[0]\r\n",
        "upper_loser4 = np.asarray(loser4_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner4 = np.asarray(winner4_results[4:5][0])[0]\r\n",
        "median_winner4 = np.asarray(winner4_results[9:10][0])[0]\r\n",
        "upper_winner4 = np.asarray(winner4_results[14:15][0])[0]"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN6pn6cNGyGZ"
      },
      "source": [
        "# Iteration5 :\r\n",
        "\r\n",
        "slice5 = 4\r\n",
        "\r\n",
        "loser5 = [train_regret_loser_1[slice5],\r\n",
        "       train_regret_loser_2[slice5],\r\n",
        "       train_regret_loser_3[slice5],\r\n",
        "       train_regret_loser_4[slice5],\r\n",
        "       train_regret_loser_5[slice5],\r\n",
        "       train_regret_loser_6[slice5],\r\n",
        "       train_regret_loser_7[slice5],\r\n",
        "       train_regret_loser_8[slice5],\r\n",
        "       train_regret_loser_9[slice5],\r\n",
        "       train_regret_loser_10[slice5],\r\n",
        "       train_regret_loser_11[slice5],\r\n",
        "       train_regret_loser_12[slice5],\r\n",
        "       train_regret_loser_13[slice5],\r\n",
        "       train_regret_loser_14[slice5],\r\n",
        "       train_regret_loser_15[slice5],\r\n",
        "       train_regret_loser_16[slice5],\r\n",
        "       train_regret_loser_17[slice5],\r\n",
        "       train_regret_loser_18[slice5],\r\n",
        "       train_regret_loser_19[slice5],\r\n",
        "       train_regret_loser_20[slice5]]\r\n",
        "\r\n",
        "winner5 = [train_regret_winner_1[slice5],\r\n",
        "       train_regret_winner_2[slice5],\r\n",
        "       train_regret_winner_3[slice5],\r\n",
        "       train_regret_winner_4[slice5],\r\n",
        "       train_regret_winner_5[slice5],\r\n",
        "       train_regret_winner_6[slice5],\r\n",
        "       train_regret_winner_7[slice5],\r\n",
        "       train_regret_winner_8[slice5],\r\n",
        "       train_regret_winner_9[slice5],\r\n",
        "       train_regret_winner_10[slice5],\r\n",
        "       train_regret_winner_11[slice5],\r\n",
        "       train_regret_winner_12[slice5],\r\n",
        "       train_regret_winner_13[slice5],\r\n",
        "       train_regret_winner_14[slice5],\r\n",
        "       train_regret_winner_15[slice5],\r\n",
        "       train_regret_winner_16[slice5],\r\n",
        "       train_regret_winner_17[slice5],\r\n",
        "       train_regret_winner_18[slice5],\r\n",
        "       train_regret_winner_19[slice5],\r\n",
        "       train_regret_winner_20[slice5]]\r\n",
        "\r\n",
        "loser5_results = pd.DataFrame(loser5).sort_values(by=[0], ascending=False)\r\n",
        "winner5_results = pd.DataFrame(winner5).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser5 = np.asarray(loser5_results[4:5][0])[0]\r\n",
        "median_loser5 = np.asarray(loser5_results[9:10][0])[0]\r\n",
        "upper_loser5 = np.asarray(loser5_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner5 = np.asarray(winner5_results[4:5][0])[0]\r\n",
        "median_winner5 = np.asarray(winner5_results[9:10][0])[0]\r\n",
        "upper_winner5 = np.asarray(winner5_results[14:15][0])[0]"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urt-8ta6GyYX"
      },
      "source": [
        "# Iteration6 :\r\n",
        "\r\n",
        "slice6 = 5\r\n",
        "\r\n",
        "loser6 = [train_regret_loser_1[slice6],\r\n",
        "       train_regret_loser_2[slice6],\r\n",
        "       train_regret_loser_3[slice6],\r\n",
        "       train_regret_loser_4[slice6],\r\n",
        "       train_regret_loser_5[slice6],\r\n",
        "       train_regret_loser_6[slice6],\r\n",
        "       train_regret_loser_7[slice6],\r\n",
        "       train_regret_loser_8[slice6],\r\n",
        "       train_regret_loser_9[slice6],\r\n",
        "       train_regret_loser_10[slice6],\r\n",
        "       train_regret_loser_11[slice6],\r\n",
        "       train_regret_loser_12[slice6],\r\n",
        "       train_regret_loser_13[slice6],\r\n",
        "       train_regret_loser_14[slice6],\r\n",
        "       train_regret_loser_15[slice6],\r\n",
        "       train_regret_loser_16[slice6],\r\n",
        "       train_regret_loser_17[slice6],\r\n",
        "       train_regret_loser_18[slice6],\r\n",
        "       train_regret_loser_19[slice6],\r\n",
        "       train_regret_loser_20[slice6]]\r\n",
        "\r\n",
        "winner6 = [train_regret_winner_1[slice6],\r\n",
        "       train_regret_winner_2[slice6],\r\n",
        "       train_regret_winner_3[slice6],\r\n",
        "       train_regret_winner_4[slice6],\r\n",
        "       train_regret_winner_5[slice6],\r\n",
        "       train_regret_winner_6[slice6],\r\n",
        "       train_regret_winner_7[slice6],\r\n",
        "       train_regret_winner_8[slice6],\r\n",
        "       train_regret_winner_9[slice6],\r\n",
        "       train_regret_winner_10[slice6],\r\n",
        "       train_regret_winner_11[slice6],\r\n",
        "       train_regret_winner_12[slice6],\r\n",
        "       train_regret_winner_13[slice6],\r\n",
        "       train_regret_winner_14[slice6],\r\n",
        "       train_regret_winner_15[slice6],\r\n",
        "       train_regret_winner_16[slice6],\r\n",
        "       train_regret_winner_17[slice6],\r\n",
        "       train_regret_winner_18[slice6],\r\n",
        "       train_regret_winner_19[slice6],\r\n",
        "       train_regret_winner_20[slice6]]\r\n",
        "\r\n",
        "loser6_results = pd.DataFrame(loser6).sort_values(by=[0], ascending=False)\r\n",
        "winner6_results = pd.DataFrame(winner6).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser6 = np.asarray(loser6_results[4:5][0])[0]\r\n",
        "median_loser6 = np.asarray(loser6_results[9:10][0])[0]\r\n",
        "upper_loser6 = np.asarray(loser6_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner6 = np.asarray(winner6_results[4:5][0])[0]\r\n",
        "median_winner6 = np.asarray(winner6_results[9:10][0])[0]\r\n",
        "upper_winner6 = np.asarray(winner6_results[14:15][0])[0]"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQJb0cU0GybL"
      },
      "source": [
        "# Iteration7 :\r\n",
        "\r\n",
        "slice7 = 6\r\n",
        "\r\n",
        "loser7 = [train_regret_loser_1[slice7],\r\n",
        "       train_regret_loser_2[slice7],\r\n",
        "       train_regret_loser_3[slice7],\r\n",
        "       train_regret_loser_4[slice7],\r\n",
        "       train_regret_loser_5[slice7],\r\n",
        "       train_regret_loser_6[slice7],\r\n",
        "       train_regret_loser_7[slice7],\r\n",
        "       train_regret_loser_8[slice7],\r\n",
        "       train_regret_loser_9[slice7],\r\n",
        "       train_regret_loser_10[slice7],\r\n",
        "       train_regret_loser_11[slice7],\r\n",
        "       train_regret_loser_12[slice7],\r\n",
        "       train_regret_loser_13[slice7],\r\n",
        "       train_regret_loser_14[slice7],\r\n",
        "       train_regret_loser_15[slice7],\r\n",
        "       train_regret_loser_16[slice7],\r\n",
        "       train_regret_loser_17[slice7],\r\n",
        "       train_regret_loser_18[slice7],\r\n",
        "       train_regret_loser_19[slice7],\r\n",
        "       train_regret_loser_20[slice7]]\r\n",
        "\r\n",
        "winner7 = [train_regret_winner_1[slice7],\r\n",
        "       train_regret_winner_2[slice7],\r\n",
        "       train_regret_winner_3[slice7],\r\n",
        "       train_regret_winner_4[slice7],\r\n",
        "       train_regret_winner_5[slice7],\r\n",
        "       train_regret_winner_6[slice7],\r\n",
        "       train_regret_winner_7[slice7],\r\n",
        "       train_regret_winner_8[slice7],\r\n",
        "       train_regret_winner_9[slice7],\r\n",
        "       train_regret_winner_10[slice7],\r\n",
        "       train_regret_winner_11[slice7],\r\n",
        "       train_regret_winner_12[slice7],\r\n",
        "       train_regret_winner_13[slice7],\r\n",
        "       train_regret_winner_14[slice7],\r\n",
        "       train_regret_winner_15[slice7],\r\n",
        "       train_regret_winner_16[slice7],\r\n",
        "       train_regret_winner_17[slice7],\r\n",
        "       train_regret_winner_18[slice7],\r\n",
        "       train_regret_winner_19[slice7],\r\n",
        "       train_regret_winner_20[slice7]]\r\n",
        "\r\n",
        "loser7_results = pd.DataFrame(loser7).sort_values(by=[0], ascending=False)\r\n",
        "winner7_results = pd.DataFrame(winner7).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser7 = np.asarray(loser7_results[4:5][0])[0]\r\n",
        "median_loser7 = np.asarray(loser7_results[9:10][0])[0]\r\n",
        "upper_loser7 = np.asarray(loser7_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner7 = np.asarray(winner7_results[4:5][0])[0]\r\n",
        "median_winner7 = np.asarray(winner7_results[9:10][0])[0]\r\n",
        "upper_winner7 = np.asarray(winner7_results[14:15][0])[0]"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O8pwUkWGyeD"
      },
      "source": [
        "# Iteration8 :\r\n",
        "\r\n",
        "slice8 = 7\r\n",
        "\r\n",
        "loser8 = [train_regret_loser_1[slice8],\r\n",
        "       train_regret_loser_2[slice8],\r\n",
        "       train_regret_loser_3[slice8],\r\n",
        "       train_regret_loser_4[slice8],\r\n",
        "       train_regret_loser_5[slice8],\r\n",
        "       train_regret_loser_6[slice8],\r\n",
        "       train_regret_loser_7[slice8],\r\n",
        "       train_regret_loser_8[slice8],\r\n",
        "       train_regret_loser_9[slice8],\r\n",
        "       train_regret_loser_10[slice8],\r\n",
        "       train_regret_loser_11[slice8],\r\n",
        "       train_regret_loser_12[slice8],\r\n",
        "       train_regret_loser_13[slice8],\r\n",
        "       train_regret_loser_14[slice8],\r\n",
        "       train_regret_loser_15[slice8],\r\n",
        "       train_regret_loser_16[slice8],\r\n",
        "       train_regret_loser_17[slice8],\r\n",
        "       train_regret_loser_18[slice8],\r\n",
        "       train_regret_loser_19[slice8],\r\n",
        "       train_regret_loser_20[slice8]]\r\n",
        "\r\n",
        "winner8 = [train_regret_winner_1[slice8],\r\n",
        "       train_regret_winner_2[slice8],\r\n",
        "       train_regret_winner_3[slice8],\r\n",
        "       train_regret_winner_4[slice8],\r\n",
        "       train_regret_winner_5[slice8],\r\n",
        "       train_regret_winner_6[slice8],\r\n",
        "       train_regret_winner_7[slice8],\r\n",
        "       train_regret_winner_8[slice8],\r\n",
        "       train_regret_winner_9[slice8],\r\n",
        "       train_regret_winner_10[slice8],\r\n",
        "       train_regret_winner_11[slice8],\r\n",
        "       train_regret_winner_12[slice8],\r\n",
        "       train_regret_winner_13[slice8],\r\n",
        "       train_regret_winner_14[slice8],\r\n",
        "       train_regret_winner_15[slice8],\r\n",
        "       train_regret_winner_16[slice8],\r\n",
        "       train_regret_winner_17[slice8],\r\n",
        "       train_regret_winner_18[slice8],\r\n",
        "       train_regret_winner_19[slice8],\r\n",
        "       train_regret_winner_20[slice8]]\r\n",
        "\r\n",
        "loser8_results = pd.DataFrame(loser8).sort_values(by=[0], ascending=False)\r\n",
        "winner8_results = pd.DataFrame(winner8).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser8 = np.asarray(loser8_results[4:5][0])[0]\r\n",
        "median_loser8 = np.asarray(loser8_results[9:10][0])[0]\r\n",
        "upper_loser8 = np.asarray(loser8_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner8 = np.asarray(winner8_results[4:5][0])[0]\r\n",
        "median_winner8 = np.asarray(winner8_results[9:10][0])[0]\r\n",
        "upper_winner8 = np.asarray(winner8_results[14:15][0])[0]\r\n"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74IRSixNGyg5"
      },
      "source": [
        "# Iteration9 :\r\n",
        "\r\n",
        "slice9 = 8\r\n",
        "\r\n",
        "loser9 = [train_regret_loser_1[slice9],\r\n",
        "       train_regret_loser_2[slice9],\r\n",
        "       train_regret_loser_3[slice9],\r\n",
        "       train_regret_loser_4[slice9],\r\n",
        "       train_regret_loser_5[slice9],\r\n",
        "       train_regret_loser_6[slice9],\r\n",
        "       train_regret_loser_7[slice9],\r\n",
        "       train_regret_loser_8[slice9],\r\n",
        "       train_regret_loser_9[slice9],\r\n",
        "       train_regret_loser_10[slice9],\r\n",
        "       train_regret_loser_11[slice9],\r\n",
        "       train_regret_loser_12[slice9],\r\n",
        "       train_regret_loser_13[slice9],\r\n",
        "       train_regret_loser_14[slice9],\r\n",
        "       train_regret_loser_15[slice9],\r\n",
        "       train_regret_loser_16[slice9],\r\n",
        "       train_regret_loser_17[slice9],\r\n",
        "       train_regret_loser_18[slice9],\r\n",
        "       train_regret_loser_19[slice9],\r\n",
        "       train_regret_loser_20[slice9]]\r\n",
        "\r\n",
        "winner9 = [train_regret_winner_1[slice9],\r\n",
        "       train_regret_winner_2[slice9],\r\n",
        "       train_regret_winner_3[slice9],\r\n",
        "       train_regret_winner_4[slice9],\r\n",
        "       train_regret_winner_5[slice9],\r\n",
        "       train_regret_winner_6[slice9],\r\n",
        "       train_regret_winner_7[slice9],\r\n",
        "       train_regret_winner_8[slice9],\r\n",
        "       train_regret_winner_9[slice9],\r\n",
        "       train_regret_winner_10[slice9],\r\n",
        "       train_regret_winner_11[slice9],\r\n",
        "       train_regret_winner_12[slice9],\r\n",
        "       train_regret_winner_13[slice9],\r\n",
        "       train_regret_winner_14[slice9],\r\n",
        "       train_regret_winner_15[slice9],\r\n",
        "       train_regret_winner_16[slice9],\r\n",
        "       train_regret_winner_17[slice9],\r\n",
        "       train_regret_winner_18[slice9],\r\n",
        "       train_regret_winner_19[slice9],\r\n",
        "       train_regret_winner_20[slice9]]\r\n",
        "\r\n",
        "loser9_results = pd.DataFrame(loser9).sort_values(by=[0], ascending=False)\r\n",
        "winner9_results = pd.DataFrame(winner9).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser9 = np.asarray(loser9_results[4:5][0])[0]\r\n",
        "median_loser9 = np.asarray(loser9_results[9:10][0])[0]\r\n",
        "upper_loser9 = np.asarray(loser9_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner9 = np.asarray(winner9_results[4:5][0])[0]\r\n",
        "median_winner9 = np.asarray(winner9_results[9:10][0])[0]\r\n",
        "upper_winner9 = np.asarray(winner9_results[14:15][0])[0]"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJDnAlE4Gyjt"
      },
      "source": [
        "# Iteration10 :\r\n",
        "\r\n",
        "slice10 = 9\r\n",
        "\r\n",
        "loser10 = [train_regret_loser_1[slice10],\r\n",
        "       train_regret_loser_2[slice10],\r\n",
        "       train_regret_loser_3[slice10],\r\n",
        "       train_regret_loser_4[slice10],\r\n",
        "       train_regret_loser_5[slice10],\r\n",
        "       train_regret_loser_6[slice10],\r\n",
        "       train_regret_loser_7[slice10],\r\n",
        "       train_regret_loser_8[slice10],\r\n",
        "       train_regret_loser_9[slice10],\r\n",
        "       train_regret_loser_10[slice10],\r\n",
        "       train_regret_loser_11[slice10],\r\n",
        "       train_regret_loser_12[slice10],\r\n",
        "       train_regret_loser_13[slice10],\r\n",
        "       train_regret_loser_14[slice10],\r\n",
        "       train_regret_loser_15[slice10],\r\n",
        "       train_regret_loser_16[slice10],\r\n",
        "       train_regret_loser_17[slice10],\r\n",
        "       train_regret_loser_18[slice10],\r\n",
        "       train_regret_loser_19[slice10],\r\n",
        "       train_regret_loser_20[slice10]]\r\n",
        "\r\n",
        "winner10 = [train_regret_winner_1[slice10],\r\n",
        "       train_regret_winner_2[slice10],\r\n",
        "       train_regret_winner_3[slice10],\r\n",
        "       train_regret_winner_4[slice10],\r\n",
        "       train_regret_winner_5[slice10],\r\n",
        "       train_regret_winner_6[slice10],\r\n",
        "       train_regret_winner_7[slice10],\r\n",
        "       train_regret_winner_8[slice10],\r\n",
        "       train_regret_winner_9[slice10],\r\n",
        "       train_regret_winner_10[slice10],\r\n",
        "       train_regret_winner_11[slice10],\r\n",
        "       train_regret_winner_12[slice10],\r\n",
        "       train_regret_winner_13[slice10],\r\n",
        "       train_regret_winner_14[slice10],\r\n",
        "       train_regret_winner_15[slice10],\r\n",
        "       train_regret_winner_16[slice10],\r\n",
        "       train_regret_winner_17[slice10],\r\n",
        "       train_regret_winner_18[slice10],\r\n",
        "       train_regret_winner_19[slice10],\r\n",
        "       train_regret_winner_20[slice10]]\r\n",
        "\r\n",
        "loser10_results = pd.DataFrame(loser10).sort_values(by=[0], ascending=False)\r\n",
        "winner10_results = pd.DataFrame(winner10).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser10 = np.asarray(loser10_results[4:5][0])[0]\r\n",
        "median_loser10 = np.asarray(loser10_results[9:10][0])[0]\r\n",
        "upper_loser10 = np.asarray(loser10_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner10 = np.asarray(winner10_results[4:5][0])[0]\r\n",
        "median_winner10 = np.asarray(winner10_results[9:10][0])[0]\r\n",
        "upper_winner10 = np.asarray(winner10_results[14:15][0])[0]"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGDzLGoCGyl7"
      },
      "source": [
        "### Summarize arrays: 'Loser'\r\n",
        "\r\n",
        "lower_loser = [lower_loser1,\r\n",
        "            lower_loser2,\r\n",
        "            lower_loser3,\r\n",
        "            lower_loser4,\r\n",
        "            lower_loser5,\r\n",
        "            lower_loser6,\r\n",
        "            lower_loser7,\r\n",
        "            lower_loser8,\r\n",
        "            lower_loser9,\r\n",
        "            lower_loser10,\r\n",
        "            lower_loser11]\r\n",
        "\r\n",
        "median_loser = [median_loser1,\r\n",
        "            median_loser2,\r\n",
        "            median_loser3,\r\n",
        "            median_loser4,\r\n",
        "            median_loser5,\r\n",
        "            median_loser6,\r\n",
        "            median_loser7,\r\n",
        "            median_loser8,\r\n",
        "            median_loser9,\r\n",
        "            median_loser10,\r\n",
        "            median_loser11]\r\n",
        "\r\n",
        "upper_loser = [upper_loser1,\r\n",
        "            upper_loser2,\r\n",
        "            upper_loser3,\r\n",
        "            upper_loser4,\r\n",
        "            upper_loser5,\r\n",
        "            upper_loser6,\r\n",
        "            upper_loser7,\r\n",
        "            upper_loser8,\r\n",
        "            upper_loser9,\r\n",
        "            upper_loser10,\r\n",
        "            upper_loser11]"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0FWrtVXGyov"
      },
      "source": [
        "### Summarize arrays: 'Winner'\r\n",
        "\r\n",
        "lower_winner = [lower_winner1,\r\n",
        "            lower_winner2,\r\n",
        "            lower_winner3,\r\n",
        "            lower_winner4,\r\n",
        "            lower_winner5,\r\n",
        "            lower_winner6,\r\n",
        "            lower_winner7,\r\n",
        "            lower_winner8,\r\n",
        "            lower_winner9,\r\n",
        "            lower_winner10,\r\n",
        "            lower_winner11]\r\n",
        "\r\n",
        "median_winner = [median_winner1,\r\n",
        "            median_winner2,\r\n",
        "            median_winner3,\r\n",
        "            median_winner4,\r\n",
        "            median_winner5,\r\n",
        "            median_winner6,\r\n",
        "            median_winner7,\r\n",
        "            median_winner8,\r\n",
        "            median_winner9,\r\n",
        "            median_winner10,\r\n",
        "            median_winner11]\r\n",
        "\r\n",
        "upper_winner = [upper_winner1,\r\n",
        "            upper_winner2,\r\n",
        "            upper_winner3,\r\n",
        "            upper_winner4,\r\n",
        "            upper_winner5,\r\n",
        "            upper_winner6,\r\n",
        "            upper_winner7,\r\n",
        "            upper_winner8,\r\n",
        "            upper_winner9,\r\n",
        "            upper_winner10,\r\n",
        "            upper_winner11]"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1CIOmuxGyq6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "66ce88e5-16cf-447f-8417-99bfdc182fd2"
      },
      "source": [
        "### Visualize!\r\n",
        "\r\n",
        "title = obj_func\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "plt.plot(median_loser, color = 'Red')\r\n",
        "plt.plot(median_winner, color = 'Yellow')\r\n",
        "\r\n",
        "xstar = np.arange(0, max_iter+1, step=1)\r\n",
        "plt.fill_between(xstar, lower_winner, upper_winner, facecolor = 'Yellow', alpha=0.4, label='GP EI Regret IQR: L-BFGS-B')\r\n",
        "plt.fill_between(xstar, lower_loser, upper_loser, facecolor = 'Red', alpha=0.4, label='GP EI Regret IQR: Newton-CG with GP d$^{2}$EI')\r\n",
        "\r\n",
        "plt.title(title, weight = 'bold')\r\n",
        "plt.xlabel('(Post-initialization) iteration $\\it{k}$', weight = 'bold', family = 'Arial') # x-axis label\r\n",
        "plt.ylabel('log(Regret)', weight = 'bold', family = 'Arial') # y-axis label\r\n",
        "plt.legend(loc=1) # add plot legend\r\n",
        "\r\n",
        "plt.show() #visualize"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id2Uf2m8KF4T"
      },
      "source": [
        "## 'Loser' and 'Winner' are terms used to differentiate between the 1st surrogate vs. 2nd surrogate \r\n",
        "\r\n",
        "## In this example the 'Loser' surrogate i.e. Newton-CG + Exact Hessian minimizes training regret IQR versus the 'winner' i.e. L-BFGS-B"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psyLOs-MGytY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad99a33-9ff0-45d0-8666-c5c32c94fd26"
      },
      "source": [
        "lower_winner11, median_winner11, upper_winner11"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.973097896282471, 8.955060950631902, 8.878776071707552)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGJk2ehuJobR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c74d872-9029-4a8c-a556-38cb3f3e92f9"
      },
      "source": [
        "y_low_win = np.exp(lower_winner11)\r\n",
        "y_median_win = np.exp(median_winner11)\r\n",
        "y_upper_win = np.exp(upper_winner11)\r\n",
        "\r\n",
        "y_low_win, y_median_win, y_upper_win"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7888.000000000001, 7746.999999999994, 7177.999999999996)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPGhgpdkfwZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffde90c4-acd9-48fd-c4b3-21cf265a2cc1"
      },
      "source": [
        "f_syn_polarity(0.5683654)\r\n",
        "\r\n",
        "## x = 56.84 days corresponds to the median training regret of y = 7,747 daily cases"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7747.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Yk6XJAIoEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0241bd6-efed-44d2-b2bd-ee0a06390e60"
      },
      "source": [
        "lower_loser11, median_loser11, upper_loser11"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.973097896282471, 8.955060950631902, 8.852521917335372)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GOrmWNtROQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef8b3d0-2669-4e20-e230-1ad716c5e430"
      },
      "source": [
        "y_low_lose = np.exp(lower_loser11)\r\n",
        "y_median_lose = np.exp(median_loser11)\r\n",
        "y_upper_lose = np.exp(upper_loser11)\r\n",
        "\r\n",
        "y_low_lose, y_median_lose, y_upper_lose"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7888.000000000001, 7746.999999999994, 6992.000000000001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSmOe-ZFgWDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688b2010-d552-4acb-e13f-7806f1ff3f6e"
      },
      "source": [
        "f_syn_polarity(0.5683654)\r\n",
        "\r\n",
        "## x = 56.84 days corresponds to the median training regret of y = 7,747 daily cases"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7747.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbXDCg4So7bO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725509df-9146-442f-a23d-6f5a101fc23a"
      },
      "source": [
        "time_lose, time_win"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1429.9792416095734, 1247.4514355659485)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTz953WagdoM"
      },
      "source": [
        ""
      ],
      "execution_count": 98,
      "outputs": []
    }
  ]
}